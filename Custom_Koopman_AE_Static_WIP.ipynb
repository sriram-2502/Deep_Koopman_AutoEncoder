{"cells":[{"cell_type":"markdown","metadata":{"id":"hrXv0rU9sIma"},"source":["# Implement a custom Autoencoder with Koopman layer"]},{"cell_type":"markdown","metadata":{},"source":["## Version Control"]},{"cell_type":"markdown","metadata":{},"source":["To Do:\n","1) Account for trailing batch - Make robust (fixed issue by reshaping input data)\n","2) Get Koopman operator, K\n","3) Preprocess Data\n","4) Make sure sim data is different for different ground parameters\n","5) Use static Koopman AE to train and get Koopman\n","6) Add a encoder model to get koopman eigenfunctions\n","\n","\n","Progress so far: Decoder+koopman works, Autoencoder does not work\n","Test: \n","Add encoder+koopman and train\n","Add encder + koopman decoder and train"]},{"cell_type":"markdown","metadata":{"id":"3LXMVuV0VhDr"},"source":["## Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-02-26T02:24:32.808146Z","iopub.status.busy":"2022-02-26T02:24:32.807594Z","iopub.status.idle":"2022-02-26T02:24:35.841571Z","shell.execute_reply":"2022-02-26T02:24:35.840833Z"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1649697591026,"user":{"displayName":"Sri Ram","userId":"08645352860667302995"},"user_tz":240},"id":"NiolgWMPgpwI"},"outputs":[],"source":["import tensorflow as tf\n","from matplotlib import pyplot as plt\n","from tensorflow import keras\n","from sklearn.model_selection import train_test_split\n","import  numpy as np\n","import pandas as pd\n","import time\n","from datetime import datetime"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1649697591026,"user":{"displayName":"Sri Ram","userId":"08645352860667302995"},"user_tz":240},"id":"Iqo002C_dKA-"},"outputs":[],"source":["plt.rcParams['figure.figsize'] = [9, 6]\n","colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":779,"status":"ok","timestamp":1649697592846,"user":{"displayName":"Sri Ram","userId":"08645352860667302995"},"user_tz":240},"id":"gjzUWH8FdO-d","outputId":"29a19841-26b1-4ec4-96ee-1a44e74e40c7"},"outputs":[],"source":["#from google.colab import drive\n","#drive.mount('/gdrive')"]},{"cell_type":"markdown","metadata":{},"source":["Comment out if don't need"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["gpus = tf.config.experimental.list_physical_devices('GPU')\n","if gpus:\n","    try:\n","        # Currently, memory growth needs to be the same across GPUs\n","        for gpu in gpus:\n","            tf.config.experimental.set_memory_growth(gpu, True)\n","        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n","        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n","    except RuntimeError as e:\n","        # Memory growth must be set before GPUs have been initialized\n","        print(e)"]},{"cell_type":"markdown","metadata":{"id":"qutT_fkl_CBc"},"source":["## Data"]},{"cell_type":"markdown","metadata":{"id":"o507HMJkdKA_"},"source":["**Dyanmics of the Simple Pendulum**\n","\n","\n","![dynamics](\\images\\dynamics.PNG)\n","\n","\n","$\\lambda = -1$\n","$\\mu = -0.05$"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":395,"status":"ok","timestamp":1649697594571,"user":{"displayName":"Sri Ram","userId":"08645352860667302995"},"user_tz":240},"id":"mbf4rGRodKBA"},"outputs":[],"source":["discrete_train = pd.read_csv('data/DiscreteSpectrumExample_train1_x.csv', sep=',', header=None).values\n","discrete_test =pd.read_csv('data/DiscreteSpectrumExample_test_x.csv', sep=',', header=None).values\n","discrete_val = pd.read_csv('data/DiscreteSpectrumExample_val_x.csv', sep=',', header=None).values"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["trajLength = int(2^6) #length of each trajectory in the dataset\n","numTraj = int(2^10) #total number of trajectories in the dataset\n","\n","batch_size = int(512)\n","numTraj_batch = int(batch_size/trajLength)\n","\n","num_batches = int(batch_size/trajLength)\n","input_dim = 2"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":227,"status":"ok","timestamp":1649697595911,"user":{"displayName":"Sri Ram","userId":"08645352860667302995"},"user_tz":240},"id":"oC-2Gx9KdKBB"},"outputs":[],"source":["# Normalize the data\n","min_val = tf.reduce_min(discrete_train)\n","max_val = tf.reduce_max(discrete_train)\n","\n","discrete_train = (discrete_train - min_val) / (max_val - min_val)\n","discrete_test = (discrete_test - min_val) / (max_val - min_val)\n","\n","train_data = tf.cast(discrete_train, tf.float32)\n","test_data = tf.cast(discrete_test, tf.float32)"]},{"cell_type":"markdown","metadata":{},"source":["## Preprocess data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["x_train = train_data\n","y_train = train_data\n","\n","tf.shape(x_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":390},"executionInfo":{"elapsed":741,"status":"ok","timestamp":1649697596968,"user":{"displayName":"Sri Ram","userId":"08645352860667302995"},"user_tz":240},"id":"fSTd03FBdKBC","outputId":"f644b1bc-7ad4-40ed-9132-548d68e56592"},"outputs":[],"source":["trail = train_data[trajLength*100:trajLength*110,:]\n","plt.grid()\n","plt.plot(x_train) #51 samples for each trajectory\n","plt.title(\"x1 and x2 vs time\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"gFzH64Jn9PIm"},"source":["# Custom Model definition"]},{"cell_type":"markdown","metadata":{},"source":["## Encoder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JBNqqzArdKBE"},"outputs":[],"source":["class EncoderLayer(keras.layers.Layer):\n","    \"\"\"\n","    Custom class to create a linear layer\n","    \n","    Parameters\n","    ----------\n","    units: number of units in the layer \n","        units are assigned to the layer at the time of initialization\n","    \n","    input_shape: shape of the input (output from previous layer)\n","        input_shape is used to build the weight matrix at the time of call\n","        \n","    Return\n","    ----------\n","    W.T * x + b: tensor\n","        linear combination of weights times input + bias for the layer\n","    \"\"\"\n","    \n","    def __init__(self, units=32, name=None, act='None'):\n","        super(EncoderLayer, self).__init__(name=name)\n","        self.units = units\n","\n","    def build(self, input_shape):\n","        self.w = self.add_weight(\n","            name = 'weight',\n","            shape=(input_shape[-1], self.units),\n","            initializer=\"glorot_uniform\",\n","            trainable=True,\n","        )\n","        self.b = self.add_weight(\n","            name = 'bias',\n","            shape=(self.units,), initializer=\"zeros\", trainable=True\n","        )\n","        #print(\"Encoder Layer, weight dimension:\",tf.shape(self.w))\n","\n","    def call(self, inputs):\n","        #print(\"Encoder Layer, output dimension:\",tf.shape(tf.matmul(inputs, self.w) + self.b))\n","        return tf.matmul(inputs, self.w) + self.b"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class EncoderModel(keras.Model):\n","    \"\"\"\n","    Custom Model to create an encoder with one input\n","    \n","    Parameters\n","    ----------\n","    input: tensor \n","        x - the the orignal state inputs x given as snapshots taken from random trajectory\n","    \n","    Return\n","    ----------\n","    z: tensor\n","        Latent variables of x in the lifted space\n","    \"\"\"\n","    \n","    def __init__(self, name=None, act='None'):\n","        super(EncoderModel, self).__init__(name=name)\n","        self.enc1 = EncoderLayer(32)\n","        self.enc2 = EncoderLayer(64)\n","        self.enc3 = EncoderLayer(128)\n","\n","    def call(self, input):\n","        x = input\n","        x = self.enc1(x)\n","        x = tf.nn.elu(x)\n","        x = self.enc2(x)\n","        x = tf.nn.elu(x)\n","\n","        # Encoder output layer\n","        z = self.enc3(x)\n","        z = tf.nn.elu(z)\n","        return z\n","\n","enc_model = EncoderModel()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"Input X:\",tf.shape(x_train))\n","Z = enc_model(x_train)\n","print(\"Encoder Output Z:\",tf.shape(Z))"]},{"cell_type":"markdown","metadata":{},"source":["## Koopman"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cUHDjcP4dKBE"},"outputs":[],"source":["class KoopmanLayer(keras.layers.Layer):\n","    \"\"\"\n","    Custom class to calculate the Koopman operator K on latent variables\n","    Adds a linear loss as mse(Z2-Z2_tilde)\n","    \n","    Parameters\n","    ----------\n","    Z: tensor \n","        inputs are the latent variabes (output from encoder)\n","        input dimension is (m, 128)\n","        m is the number of time snapshots for each input dimension of X\n","        128 is the number of latent varibales (observables)\n","\n","    Return\n","    ----------\n","    Z: tensor\n","        return the original input Z \n","\n","    Z2_tilde: tensor\n","        return the prediction by linearity from K (z2_tilde = K^m * z(1,:))\n","    \"\"\"\n","\n","    def __init__(self, trajLength, numTraj):\n","        super(KoopmanLayer, self).__init__()\n","        self.trajLength = trajLength\n","        self.numTraj = numTraj\n","\n","    def build(self, Z):\n","        # Initialize K as a weight\n","            self.K =  self.add_weight(\n","                name = 'Koopman_weight',\n","                shape=(Z[-1], Z[-1]),\n","                initializer=\"random_normal\",\n","                trainable=True,\n","            )\n","\n","    def timeShift(self,Z,latent_dim):\n","        '''\n","        Shifts trajectories one time step\n","        Parameters:\n","        -----------\n","            Z: tensor\n","                Batch data of latent variables (in the lifted space)\n","                \n","            latent_dim: tensor shape\n","                Dimension of the lifted space (columns of Z)\n","        '''\n","        Z1 = []\n","        z1 = []\n","        Z2 = []\n","\n","        for i in range(self.numTraj):\n","            Z1.append(Z[i*self.trajLength:(i+1)*self.trajLength-1,:])\n","            Z2.append(Z[i*self.trajLength+1:(i+1)*self.trajLength,:])\n","            z1.append(Z[i*self.trajLength,:])\n","        \n","        print(\"Koopman layer, z1\",tf.shape(z1))\n","        print(\"Koopman layer, Z2 \",tf.shape(Z2))\n","        return tf.reshape(Z1, [-1, latent_dim]), tf.reshape(Z2, [-1, latent_dim]), tf.reshape(z1, [-1, latent_dim])       \n","\n","    def call(self, Z):\n","        latent_dim = tf.shape(Z)[1]\n","        shift_len = (self.trajLength-1)*self.numTraj # length of rows for forward time shifted Z\n","        print(\"inside K, trajLength\", self.trajLength)\n","        Z1, Z2, z1 = self.timeShift(Z,latent_dim)\n","\n","        # Find Z2_tilde\n","        Z2_tilde = tf.zeros([shift_len, latent_dim], dtype=tf.float32)\n","        for traj in range(self.numTraj): # loop over numnber of traj\n","            for m in range(self.trajLength-1): #loop over snapshots in each traj\n","                 indices = tf.constant([[traj*self.trajLength]])\n","                 if m == 0: \n","                     updates = [tf.linalg.matvec(self.K, z1[0,:])]\n","                     tf.tensor_scatter_nd_update(Z2_tilde, indices, updates)\n","                 else:\n","                    updates = [tf.linalg.matvec(tf.matmul(self.K,self.K), z1[traj,:])]\n","                    tf.tensor_scatter_nd_update(Z2_tilde, indices, updates)\n","                    \n","        # Find linear loss\n","        Linear_loss = tf.reduce_mean(tf.square(Z2-Z2_tilde))\n","        self.add_loss(Linear_loss)\n","        \n","        # prints for debugging dimensions\n","        #print(\"Koopman layer, K\",tf.shape(K))\n","        #print(\"Koopman layer, m\",tf.shape(m))\n","        #print(\"Koopman layer, Z\",tf.shape(Z))\n","        #print(\"Koopman layer, z1\",tf.shape(z1))\n","        #print(\"Koopman layer, Z2 \",tf.shape(Z2))\n","        #print(\"Koopman layer, Z2_tilde\",tf.shape(Z2_tilde))\n","\n","        return Z, Z2_tilde"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class Koopman_Model(keras.Model):\n","    \"\"\"\n","    Custom Model to create an encoder with koopman layer\n","    \n","    Parameters\n","    ----------\n","    input: tensor \n","        z - the the orignal state inputs x given as snapshots taken from random trajectory\n","    \n","    Return\n","    ----------\n","    z: tensor\n","        Latent variables of x in the lifted space\n","\n","    z2_tilde: tensor\n","        Latent variables of prediction obtained by linearity from K (z2_tilde = K^m * z(1,:))\n","        \n","    K: tensor\n","        Koopman operator in the lifted space\n","    \"\"\"\n","    \n","    def __init__(self, trajLength, numTraj , name=None, act='None'):\n","        super(Koopman_Model, self).__init__(name=name)\n","        self.koopman = KoopmanLayer(trajLength,numTraj)\n","\n","\n","    def call(self, input):\n","        z = input\n","        z, z2_tilde = self.koopman(z)\n","        return z, z2_tilde\n","\n","\n","koop_model = Koopman_Model(trajLength,numTraj_batch)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"Input X:\",tf.shape(x_train))\n","print(\"Input x:\", tf.shape(x_train[0:64*1024,:]))\n","\n","\n","Z, Z2_tilde = koop_model(x_train)\n","print(\"Koopman Layer Z:\",tf.shape(Z))\n","print(\"Koopman Layer Z2_tilde:\",tf.shape(Z2_tilde))\n","print(\"Koopman Layer K:\",tf.shape(K))"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["class Encoder_Koopman_Model(keras.Model):\n","    \"\"\"\n","    Custom Model to create an encoder with koopman layer\n","    \n","    Parameters\n","    ----------\n","    input: tensor \n","        z - the the orignal state inputs x given as snapshots taken from random trajectory\n","    \n","    Return\n","    ----------\n","    z: tensor\n","        Latent variables of x in the lifted space\n","\n","    z2_tilde: tensor\n","        Latent variables of prediction obtained by linearity from K (z2_tilde = K^m * z(1,:))\n","        \n","    K: tensor\n","        Koopman operator in the lifted space\n","    \"\"\"\n","    \n","    def __init__(self, trajLength, numTraj , name=None, act='None'):\n","        super(Encoder_Koopman_Model, self).__init__(name=name)\n","        self.enc = EncoderModel()\n","        self.koopman = KoopmanLayer(trajLength,numTraj)\n","\n","\n","    def call(self, input):\n","        x = input\n","        z = self.enc(x)\n","        z, z2_tilde = self.koopman(z)\n","        return z, z2_tilde\n","\n","enc_koop_model = Encoder_Koopman_Model(trajLength,numTraj_batch)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"Input X:\",tf.shape(x_train))\n","Z, Z2_tilde = enc_koop_model(x_train)\n","print(\"Koopman Layer Z:\",tf.shape(Z))\n","print(\"Koopman Layer Z2_tilde:\",tf.shape(Z2_tilde))"]},{"cell_type":"markdown","metadata":{},"source":["## Decoder"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class DecoderLayer(keras.layers.Layer):\n","    \"\"\"\n","    Custom class to create a decoder layer with two inputs\n","    \n","    Parameters\n","    ----------\n","    units: number of units in the layer \n","        units are assigned to the layer at the time of initialization\n","    \n","    input_shape: shape of the input (output from previous layer)\n","        input_shape is used to build the weight matrix at the time of call\n","        \n","    Return\n","    ----------\n","    W.T * input1 + b: tensor\n","        linear combination of weights times input1 + bias for the layer\n","        \n","    W.T * input2 + b: tensor\n","        linear combination of weights times input2 + bias for the layer\n","    \"\"\"\n","\n","    def __init__(self, units=32, name=None):\n","        super(DecoderLayer, self).__init__(name=name)\n","        self.units = units\n","\n","    def build(self, input_shape):\n","        self.w = self.add_weight(\n","            name = 'weight',\n","            shape=(input_shape[-1], self.units),\n","            initializer=\"glorot_uniform\",\n","            trainable=True,\n","        )\n","        self.b = self.add_weight(\n","            name = 'bias',\n","            shape=(self.units,), initializer=\"zeros\", trainable=True\n","        )\n","        #print(\"Decoder Layer, weight dimension:\",tf.shape(self.w))\n","\n","    def call(self, input1, input2):\n","        #print(\"Decoder Layer, output dimension:\",tf.shape(tf.matmul(inputs, self.w) + self.b))\n","        return tf.matmul(input1, self.w) + self.b, tf.matmul(input2, self.w) + self.b"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class DecoderModel(keras.Model):\n","    \"\"\"\n","    Custom Model to create a decoder with two inputs\n","    \n","    Parameters\n","    ----------\n","    input 1: tensor \n","        z - the lifted output of the koopman layer (encoder output)\n","    \n","    input 2: tensor \n","        z2_tilde - obtained by linearity from K (z2_tilde = K^m * z(1,:))\n","        \n","    Return\n","    ----------\n","    x_hat: tensor\n","        Reconstuction of the orignal state inputs x (label values are x)\n","    \n","    x2_hat: tensor\n","        Predcition of the original state inputs x (label values are forward time shifted x)\n","    \"\"\"\n","    \n","    def __init__(self, name=None, act='None'):\n","        super(DecoderModel, self).__init__(name=name)\n","        self.dec1 = DecoderLayer(64)\n","        self.dec2 = DecoderLayer(32)\n","        self.outputLayer = DecoderLayer(2)\n","\n","    def call(self, input1, input2):\n","        z = input1\n","        z2_tilde = input2\n","\n","        z, z2_tilde = self.dec1(z, z2_tilde)\n","        z = tf.nn.elu(z)\n","        z2_tilde = tf.nn.elu(z2_tilde)\n","\n","        z, z2_tilde = self.dec2(z, z2_tilde)\n","        z = tf.nn.elu(z)\n","        z2_tilde = tf.nn.elu(z2_tilde)\n","\n","        # Decoder output layer\n","        x_hat, x2_hat = self.outputLayer(z, z2_tilde)\n","        x_hat = tf.nn.elu(x_hat)\n","        x2_hat = tf.nn.elu(x2_hat)\n","\n","        return x_hat, x2_hat\n","\n","dec_model = DecoderModel(trajLength,numTraj_batch)"]},{"cell_type":"markdown","metadata":{},"source":["## Decoder with Koopman "]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[],"source":["class Koopman_DecoderModel(keras.Model):\n","    \"\"\"\n","    Custom Model to create a decoder with two inputs\n","    \n","    Parameters\n","    ----------\n","    input 1: tensor \n","        z - the lifted output of the koopman layer (encoder output)\n","    \n","    input 2: tensor \n","        z2_tilde - obtained by linearity from K (z2_tilde = K^m * z(1,:))\n","        \n","    Return\n","    ----------\n","    x_hat: tensor\n","        Reconstuction of the orignal state inputs x (label values are x)\n","    \n","    x2_hat: tensor\n","        Predcition of the original state inputs x (label values are forward time shifted x)\n","    \"\"\"\n","    \n","    def __init__(self, trajLength, numTraj):\n","        super(Koopman_DecoderModel, self).__init__()\n","        self.koopman = KoopmanLayer(trajLength,numTraj)\n","        self.dec1 = DecoderModel()\n","\n","    def call(self, input):\n","        z = input\n","        z, z2_tilde = self.koopman(z)\n","        x_hat, x2_hat = self.dec1(z, z2_tilde)\n","        return x_hat, x2_hat\n","\n","koop_dec_model = Koopman_DecoderModel(trajLength,numTraj_batch)"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Input X: tf.Tensor([65536     2], shape=(2,), dtype=int32)\n"]},{"ename":"NameError","evalue":"name 'enc_koop_model' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32mc:\\Users\\sriramk\\Downloads\\Sriram_DL_Project\\Deep_Koopaman_AutoEncoder\\Custom_Koopman_AE_Static_WIP.ipynb Cell 34'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sriramk/Downloads/Sriram_DL_Project/Deep_Koopaman_AutoEncoder/Custom_Koopman_AE_Static_WIP.ipynb#ch0000033?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mInput X:\u001b[39m\u001b[39m\"\u001b[39m,tf\u001b[39m.\u001b[39mshape(x_train))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/sriramk/Downloads/Sriram_DL_Project/Deep_Koopaman_AutoEncoder/Custom_Koopman_AE_Static_WIP.ipynb#ch0000033?line=2'>3</a>\u001b[0m Z, Z2_tilde \u001b[39m=\u001b[39m enc_koop_model(x_train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sriramk/Downloads/Sriram_DL_Project/Deep_Koopaman_AutoEncoder/Custom_Koopman_AE_Static_WIP.ipynb#ch0000033?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mKoopman Layer Output Z:\u001b[39m\u001b[39m\"\u001b[39m,tf\u001b[39m.\u001b[39mshape(Z))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/sriramk/Downloads/Sriram_DL_Project/Deep_Koopaman_AutoEncoder/Custom_Koopman_AE_Static_WIP.ipynb#ch0000033?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mKoopman Layer Output Z2_tilde:\u001b[39m\u001b[39m\"\u001b[39m,tf\u001b[39m.\u001b[39mshape(Z2_tilde))\n","\u001b[1;31mNameError\u001b[0m: name 'enc_koop_model' is not defined"]}],"source":["print(\"Input X:\",tf.shape(x_train))\n","\n","Z, Z2_tilde = enc_koop_model(x_train)\n","print(\"Koopman Layer Output Z:\",tf.shape(Z))\n","print(\"Koopman Layer Output Z2_tilde:\",tf.shape(Z2_tilde))\n","\n","X_hat, X2_hat = dec_model(Z, Z2_tilde)\n","print(\"Decoder Output X_hat:\",tf.shape(X_hat))\n","print(\"Decoder Output X2_hat:\",tf.shape(X2_hat))\n","\n","print(\"Lables X:\",tf.shape(x_train))\n","X2 = []\n","for i in range(numTraj):\n","    X2.append(x_train[i*trajLength+1:(i+1)*trajLength,:])\n","X2 = tf.reshape(X2, [-1, x_train.shape[-1]])\n","print(\"Labels X2:\",tf.shape(X2))"]},{"cell_type":"markdown","metadata":{},"source":["## Koopman Autoencoder"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class Koopman_AE(keras.Model):\n","    \"\"\"\n","    Custom Model to create a Koopman Autoencoder\n","    \n","    Parameters\n","    ----------\n","    input: tensor \n","        x - the the orignal state inputs x given as snapshots taken from random trajectory\n","    \n","    Return\n","    ----------\n","    x_hat: tensor\n","        Reconstuction of the orignal state inputs x (label values are x)\n","    \n","    x2_hat: tensor\n","        Predcition of the original state inputs x (label values are forward time shifted x)\n","    \"\"\"\n","    \n","    def __init__(self, trajLength, numTraj , name=None, act='None'):\n","        super(Koopman_AE, self).__init__(name=name)\n","        self.enc = EncoderModel()\n","        self.koopman = Koopman_Model(trajLength, numTraj)\n","        self.dec = DecoderModel()\n","\n","    def call(self, input):\n","        x = input\n","        z = self.enc(x)\n","        z, z2_tilde = self.koopman(z)\n","        x_hat, x2_hat = self.dec(z, z2_tilde)\n","        return x_hat, x2_hat\n","        \n","koop_ae = Koopman_AE(trajLength, numTraj_batch)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"Input\",tf.shape(x_train))\n","x_hat, x2_hat = koop_ae(x_train)\n","print(\"output Layer x_hat\",tf.shape(x_hat))\n","print(\"output Layer x2_hat\",tf.shape(x2_hat))\n","print(\"input for predictions\",tf.shape(x_train[1:,:]))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["koop_ae.summary()"]},{"cell_type":"markdown","metadata":{},"source":["# Custom Training Loop"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_data))\n","train_dataset = train_dataset.batch(batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def reconstruction_loss(y_true, y_pred):\n","    \"\"\"Calculates the Mean Squared Error between y_pred and y_true vectors\"\"\"\n","    return tf.reduce_mean(tf.abs(y_true-y_pred)) #avg loss for each batch since reduce_mean is already an avg\n","\n","def prediction_loss(x, x2_hat, numTraj_batch, trajLength):\n","        \"\"\"Calculates prediction loss from x2 (time shifted x) to output x2_hat\"\"\"\n","        x2 = []\n","        for i in range(numTraj_batch):\n","            x2.append(x[i*trajLength+1:(i+1)*trajLength,:])\n","        x2 = tf.reshape(x2, [-1, x_train.shape[-1]])\n","        return tf.reduce_mean(tf.abs(x2-x2_hat)) #avg loss for each batch since reduce_mean is already an av\n","\n","def total_loss(model, recon_loss, predict_loss):\n","    \"\"\"Calculates total loss as sum of recon_loss + predict_loss + Koopman_loss\"\"\"\n","    return recon_loss + predict_loss + sum(model.losses)"]},{"cell_type":"markdown","metadata":{},"source":["## training loop for dec koopman"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Start of epoch 0\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","Training loss (for one batch) at step 0: 1.2694\n","Seen so far: 512 samples\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","Training loss (for one batch) at step 100: 1.2894\n","Seen so far: 51712 samples\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","inside K, trajLength 4\n","Koopman layer, z1 tf.Tensor([128   2], shape=(2,), dtype=int32)\n","Koopman layer, Z2  tf.Tensor([128   3   2], shape=(3,), dtype=int32)\n","Average trainig loss at epoch 0: 1.1487\n","Time taken: 45.50s\n"]}],"source":["variables = koop_dec_model.trainable_variables\n","optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)\n","epochs = 1\n","\n","total_loss_list = [] # total loss for each epoch\n","for epoch in range(epochs):\n","  batch_tot_loss_list = [] # ttal loss for each batch \n","  #reconstruction_loss_batch = []\n","  #prediction_loss_batch = []\n","  \n","  print(\"\\nStart of epoch %d\" % (epoch,))\n","  start_time = time.time()\n","\n","  # Iterate over the batches of the dataset.\n","  for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n","    with tf.GradientTape() as tape:\n","      batch_length =  len(x_batch_train) #num elements in each batch\n","      reconstruction, predictions = koop_dec_model(x_batch_train)\n","      \n","      # avg loss for each batch\n","      recon_loss =  reconstruction_loss(y_batch_train, reconstruction)\n","      predict_loss =  prediction_loss(y_batch_train, predictions, numTraj_batch, trajLength)\n","\n","      # total avg loss for each batch\n","      batch_tot_loss = total_loss(koop_dec_model,recon_loss, predict_loss)\n","      batch_tot_loss_list.append(batch_tot_loss)\n","      \n","    grads = tape.gradient(batch_tot_loss, variables)\n","    #grads = tape.gradient(batch_tot_loss, variables, unconnected_gradients=tf.UnconnectedGradients.ZERO)\n","    optimizer.apply_gradients(zip(grads, variables))\n","    \n","    # Log every 100 batches.\n","    if step % 100 == 0:\n","        print(\n","            \"Training loss (for one batch) at step %d: %.4f\"\n","            % (step, float(batch_tot_loss))\n","        )\n","        print(\"Seen so far: %s samples\" % ((step + 1) * batch_size))\n","  \n","  # outside batch loop\n","  total_loss_avg = np.sum(batch_tot_loss_list)/num_batches\n","  total_loss_list.append(total_loss_avg)\n","\n","  print(\n","          \"Average trainig loss at epoch %d: %.4f\"\n","          % (epoch, float(total_loss_avg))\n","      )\n","  print(\"Time taken: %.2fs\" % (time.time() - start_time))\n"]},{"cell_type":"markdown","metadata":{},"source":["## training loop for koopman ae"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["variables = koop_ae.trainable_variables\n","optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)\n","epochs = 1\n","\n","total_loss_list = [] # total loss for each epoch\n","for epoch in range(epochs):\n","  batch_tot_loss_list = [] # ttal loss for each batch \n","  #reconstruction_loss_batch = []\n","  #prediction_loss_batch = []\n","  \n","  print(\"\\nStart of epoch %d\" % (epoch,))\n","  start_time = time.time()\n","\n","  # Iterate over the batches of the dataset.\n","  for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n","    with tf.GradientTape() as tape:\n","      batch_length =  len(x_batch_train) #num elements in each batch\n","      reconstruction, predictions = koop_ae(x_batch_train)\n","      \n","      # avg loss for each batch\n","      recon_loss =  reconstruction_loss(y_batch_train, reconstruction)\n","      predict_loss =  prediction_loss(y_batch_train, predictions, numTraj_batch, trajLength)\n","\n","      # total avg loss for each batch\n","      batch_tot_loss = total_loss(koop_ae,recon_loss, predict_loss)\n","      batch_tot_loss_list.append(batch_tot_loss)\n","      \n","    grads = tape.gradient(batch_tot_loss, variables)\n","    #grads = tape.gradient(batch_tot_loss, variables, unconnected_gradients=tf.UnconnectedGradients.ZERO)\n","    optimizer.apply_gradients(zip(grads, variables))\n","    \n","    # Log every 100 batches.\n","    if step % 100 == 0:\n","        print(\n","            \"Training loss (for one batch) at step %d: %.4f\"\n","            % (step, float(batch_tot_loss))\n","        )\n","        print(\"Seen so far: %s samples\" % ((step + 1) * batch_size))\n","  \n","  # outside batch loop\n","  total_loss_avg = np.sum(batch_tot_loss_list)/num_batches\n","  total_loss_list.append(total_loss_avg)\n","\n","  print(\n","          \"Average trainig loss at epoch %d: %.4f\"\n","          % (epoch, float(total_loss_avg))\n","      )\n","  print(\"Time taken: %.2fs\" % (time.time() - start_time))\n"]},{"cell_type":"markdown","metadata":{},"source":["# Plots"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["input = x_train[0:510]\n","plt.plot(input)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["out1, out2, K = koop_ae(input)\n","plt.plot(out1)"]},{"cell_type":"markdown","metadata":{},"source":["# Save the Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["koop_ae.save('checkpoints/Static_koopman1')"]},{"cell_type":"markdown","metadata":{},"source":["# Load the Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["new_model = tf.keras.models.load_model('checkpoints/Static_koopman1', compile=False)\n","new_out1, new_out2, K = new_model(input)\n","plt.plot(new_out1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["new_model.summary()"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"saveExample.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}
