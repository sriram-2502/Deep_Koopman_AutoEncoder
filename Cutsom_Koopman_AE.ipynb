{"cells":[{"cell_type":"markdown","metadata":{"id":"hrXv0rU9sIma"},"source":["# Implement a custom Autoencoder with Koopman layer"]},{"cell_type":"markdown","metadata":{"id":"3LXMVuV0VhDr"},"source":["## Setup"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-02-26T02:24:32.808146Z","iopub.status.busy":"2022-02-26T02:24:32.807594Z","iopub.status.idle":"2022-02-26T02:24:35.841571Z","shell.execute_reply":"2022-02-26T02:24:35.840833Z"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1649697591026,"user":{"displayName":"Sri Ram","userId":"08645352860667302995"},"user_tz":240},"id":"NiolgWMPgpwI"},"outputs":[],"source":["import tensorflow as tf\n","from matplotlib import pyplot as plt\n","from tensorflow import keras\n","from sklearn.model_selection import train_test_split\n","import  numpy as np\n","import pandas as pd\n","import time"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Import hyperparameter tuning\n","import keras_tuner as kt"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1649697591026,"user":{"displayName":"Sri Ram","userId":"08645352860667302995"},"user_tz":240},"id":"Iqo002C_dKA-"},"outputs":[],"source":["plt.rcParams['figure.figsize'] = [9, 6]\n","colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":779,"status":"ok","timestamp":1649697592846,"user":{"displayName":"Sri Ram","userId":"08645352860667302995"},"user_tz":240},"id":"gjzUWH8FdO-d","outputId":"29a19841-26b1-4ec4-96ee-1a44e74e40c7"},"outputs":[],"source":["#from google.colab import drive\n","#drive.mount('/gdrive')"]},{"cell_type":"markdown","metadata":{"id":"qutT_fkl_CBc"},"source":["## Data"]},{"cell_type":"markdown","metadata":{"id":"o507HMJkdKA_"},"source":["**Dyanmics of the Simple Pendulum**\n","\n","\n","![dynamics](\\images\\dynamics.PNG)\n","\n","\n","$\\lambda = -1$\n","$\\mu = -0.05$"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":395,"status":"ok","timestamp":1649697594571,"user":{"displayName":"Sri Ram","userId":"08645352860667302995"},"user_tz":240},"id":"mbf4rGRodKBA"},"outputs":[],"source":["discrete_train = pd.read_csv('data/DiscreteSpectrumExample_train1_x.csv', sep=',').values\n","discrete_test =pd.read_csv('data/DiscreteSpectrumExample_test_x.csv', sep=',').values\n","discrete_val = pd.read_csv('data/DiscreteSpectrumExample_val_x.csv', sep=',').values"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":227,"status":"ok","timestamp":1649697595911,"user":{"displayName":"Sri Ram","userId":"08645352860667302995"},"user_tz":240},"id":"oC-2Gx9KdKBB"},"outputs":[],"source":["# Normalize the data\n","min_val = tf.reduce_min(discrete_train)\n","max_val = tf.reduce_max(discrete_train)\n","\n","discrete_train = (discrete_train - min_val) / (max_val - min_val)\n","discrete_test = (discrete_test - min_val) / (max_val - min_val)\n","\n","train_data = tf.cast(discrete_train, tf.float32)\n","test_data = tf.cast(discrete_test, tf.float32)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":390},"executionInfo":{"elapsed":741,"status":"ok","timestamp":1649697596968,"user":{"displayName":"Sri Ram","userId":"08645352860667302995"},"user_tz":240},"id":"fSTd03FBdKBC","outputId":"f644b1bc-7ad4-40ed-9132-548d68e56592"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 648x432 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["x_train = train_data[0:50,:]\n","plt.grid()\n","plt.plot(x_train) #51 samples for each trajectory\n","plt.title(\"x1 and x2 vs time\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"gFzH64Jn9PIm"},"source":["## Define the model"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"JBNqqzArdKBE"},"outputs":[],"source":["class EncoderLayer(keras.layers.Layer):\n","    \"\"\"\n","    Custom class to create a linear layer\n","    \n","    Parameters\n","    ----------\n","    units: number of units in the layer \n","        units are assigned to the layer at the time of initialization\n","    \n","    input_shape: shape of the input (output from previous layer)\n","        input_shape is used to build the weight matrix at the time of call\n","        \n","    Return\n","    ----------\n","    W.T * x + b: tensor\n","        linear combination of weights times input + bias for the layer\n","    \"\"\"\n","    \n","    def __init__(self, units=32, name=None, act='None'):\n","        super(EncoderLayer, self).__init__(name=name)\n","        self.units = units\n","\n","    def build(self, input_shape):\n","        self.w = self.add_weight(\n","            name = 'weight',\n","            shape=(input_shape[-1], self.units),\n","            initializer=\"glorot_uniform\",\n","            trainable=True,\n","        )\n","        self.b = self.add_weight(\n","            name = 'bias',\n","            shape=(self.units,), initializer=\"zeros\", trainable=True\n","        )\n","        #print(\"Encoder Layer, weight dimension:\",tf.shape(self.w))\n","\n","    def call(self, inputs):\n","        #print(\"Encoder Layer, output dimension:\",tf.shape(tf.matmul(inputs, self.w) + self.b))\n","        return tf.matmul(inputs, self.w) + self.b"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["class DecoderLayer(keras.layers.Layer):\n","    \"\"\"\n","    Custom class to create a linear layer\n","    \n","    Parameters\n","    ----------\n","    units: number of units in the layer \n","        units are assigned to the layer at the time of initialization\n","    \n","    input_shape: shape of the input (output from previous layer)\n","        input_shape is used to build the weight matrix at the time of call\n","        \n","    Return\n","    ----------\n","    W.T * x + b: tensor\n","        linear combination of weights times input + bias for the layer\n","    \"\"\"\n","\n","    def __init__(self, units=32, name=None):\n","        super(DecoderLayer, self).__init__(name=name)\n","        self.units = units\n","\n","    def build(self, input_shape):\n","        self.w = self.add_weight(\n","            name = 'weight',\n","            shape=(input_shape[-1], self.units),\n","            initializer=\"glorot_uniform\",\n","            trainable=True,\n","        )\n","        self.b = self.add_weight(\n","            name = 'bias',\n","            shape=(self.units,), initializer=\"zeros\", trainable=True\n","        )\n","        #print(\"Decoder Layer, weight dimension:\",tf.shape(self.w))\n","\n","    def call(self, input1, input2):\n","        #print(\"Decoder Layer, output dimension:\",tf.shape(tf.matmul(inputs, self.w) + self.b))\n","        return tf.matmul(input1, self.w) + self.b, tf.matmul(input2, self.w) + self.b"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"cUHDjcP4dKBE"},"outputs":[],"source":["class KoopmanLayer(keras.layers.Layer):\n","    \"\"\"\n","    Custom class to calculate the Koopman operator K on latent variables\n","    Adds a linear loss as mse(Z2-Z2_tilde)\n","    \n","    Parameters\n","    ----------\n","    Z: tensor \n","        inputs are the latent variabes (output from encoder)\n","        input dimension is (m, 128)\n","        m is the number of time snapshots for each input dimension of X\n","        128 is the number of latent varibales (observables)\n","\n","    Return\n","    ----------\n","    Z: tensor\n","        return the original input Z \n","\n","    Z2_tilde: tensor\n","        return the forward time shifted Z\n","    \"\"\"\n","\n","    def __init__(self, trajLength, numTraj):\n","        super(KoopmanLayer, self).__init__()\n","        self.trajLength = trajLength\n","        self.numTraj = numTraj\n","        \n","\n","    def timeShift(self,Z):\n","        '''\n","        Shifts trajectories one time step\n","        Parameters:\n","        -----------\n","            Z: tensor\n","                Batch data\n","            m: numpy element\n","                Batch size\n","        '''\n","\n","        # ******** DO EVERYTHING IN TF OR TF SLICES ****************\n","        Z1 = []\n","        z1 = []\n","        Z2 = []\n","\n","        for i in range(self.numTraj):\n","            Z1.append(Z[i*self.trajLength:(i+1)*self.trajLength-1,:])\n","            Z2.append(Z[i*self.trajLength+1:(i+1)*self.trajLength])\n","            z1.append(Z[i*self.trajLength,:])\n","\n","        # ********** GET INPUT SIZE ROBUSTLY ********************\n","        return tf.reshape(Z1, [-1, 64]), tf.reshape(Z2, [-1,64]), tf.reshape(z1, [-1,64])       \n","\n","    def call(self, Z):\n","        Z1, Z2, z1 = self.timeShift(Z)\n","        # Find K\n","        K = tf.matmul(tf.transpose(Z2),tf.linalg.pinv(tf.transpose(Z1)))\n","\n","        # Find Z2_tilde\n","        Z2_tilde = tf.zeros([500, 64], dtype=tf.float32)\n","        for traj in range(self.numTraj): # loop over numnber of traj\n","            for m in range(self.trajLength-1): #loop over snapshots in each traj\n","                 indices = tf.constant([[traj*self.trajLength]])\n","                 indices = tf.constant([[1]])\n","                 if m == 0: \n","                     updates = [tf.linalg.matvec(K, z1[0,:])]\n","                     tf.tensor_scatter_nd_update(Z2_tilde, indices, updates)\n","                 else:\n","                    Ki = K\n","                    Ki = tf.matmul(Ki,K)\n","                    updates = [tf.linalg.matvec(Ki, z1[traj,:])]\n","                    tf.tensor_scatter_nd_update(Z2_tilde, indices, updates)\n","                    \n","        # Find linear loss\n","        Linear_loss = tf.reduce_mean(tf.square(Z2-Z2_tilde))\n","        self.add_loss(Linear_loss)\n","        \n","        # prints for debugging dimensions\n","        #print(\"Koopman layer, K\",tf.shape(K))\n","        #print(\"Koopman layer, m\",tf.shape(m))\n","        #print(\"Koopman layer, Z\",tf.shape(Z))\n","        #print(\"Koopman layer, z1\",tf.shape(z1))\n","        #print(\"Koopman layer, Z2 \",tf.shape(Z2))\n","        #print(\"Koopman layer, Z2_tilde\",tf.shape(Z2_tilde))\n","\n","        return Z, Z2_tilde"]},{"cell_type":"markdown","metadata":{},"source":["### Hyperparameter Tuning"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["num_batches = 2\n","batch_size = 510\n","train_dataset = tf.data.Dataset.from_tensor_slices((train_data[0:batch_size*num_batches,:], train_data[0:batch_size*num_batches,:]))\n","train_dataset = train_dataset.batch(batch_size)\n","x_train = train_data[0:batch_size*num_batches]\n","y_train = train_data[0:batch_size*num_batches]"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[],"source":["# Hyperparameter Class\n","\n","class MyHyperModel(kt.HyperModel):\n","    def build(self, hp):\n","        inputs = tf.keras.layers.Input(shape=(2,))\n","\n","        \n","        trajLength = int(51)\n","        numtraj = int(510/51)\n","        encoder_1 = EncoderLayer(16)\n","        encoder_2 = EncoderLayer(32)\n","        encoder_3 = EncoderLayer(64)\n","        koopman = KoopmanLayer(trajLength, numtraj)\n","        decoder_1 = DecoderLayer(32)\n","        decoder_2 = DecoderLayer(16)\n","        outputLayer = DecoderLayer(2)\n","        \n","        # input layer\n","        #x = x[:, :, tf.newaxis] #fixes dimension issues with input\n","\n","        # encoding layers (linear layer)\n","\n","        x = encoder_1(inputs) # Put hyperparameter input size\n","        x = tf.nn.elu(x)\n","        x = encoder_2(x)\n","        x = tf.nn.elu(x)\n","        x = encoder_3(x)\n","        z = tf.nn.elu(x)\n","\n","        # koopman layer\n","        z, z2_tilde  = koopman(z)\n","\n","        # decoding layers for x\n","        z, z2_tilde = decoder_1(z, z2_tilde)\n","        z = tf.nn.elu(z)\n","        z2_tilde = tf.nn.elu(z2_tilde)\n","\n","        z,z2_tilde = decoder_2(z, z2_tilde)\n","        z = tf.nn.elu(z)\n","        z2_tilde = tf.nn.elu(z2_tilde)\n","        \n","        # output layer\n","        x_hat, x2_hat = outputLayer(z, z2_tilde)\n","        #x_hat = tf.nn.relu(z)\n","\n","        # Build the model with one input and two outputs\n","        ae = tf.keras.models.Model(\n","            inputs=inputs, outputs=[x_hat, x2_hat], name=\"Deep_Koopman_Autoencoder\")\n","        return ae\n","\n","\n","\n","\n","    def custom_loss(self, y_true, y_pred):\n","        \"\"\"Calculates the Mean Squared Error between y_pred and y_true vectors\"\"\"\n","        return tf.reduce_mean(tf.abs(y_true-y_pred)) #avg loss for each batch since reduce_mean is already an avg\n","\n","    def tot_loss(self, model, recon_loss):\n","        return recon_loss + sum(model.losses)\n","\n","\n","\n","\n","    def fit(self, hp, model, x, y, validation_data, callbacks=None, **kwargs):\n","        # Preprocess data\n","\n","        batch_size = 510\n","        train_ds = tf.data.Dataset.from_tensor_slices((x, y)).batch(\n","            batch_size\n","        )\n","\n","        # Define weights that are trainable\n","        variables = model.variables\n","\n","        # Define the optimizer\n","        optimizer = tf.keras.optimizers.SGD(hp.Float(\"learning_rate\", 1e-4, 1e-2, sampling=\"log\", default=1e-3))\n","\n","        # Metric to track validation loss\n","        epoch_loss_metric = keras.metrics.Mean()\n","        epochs = 2\n","\n","        def run_train_step(x_batch_train,y_batch_train):\n","            with tf.GradientTape() as tape:\n","                #batch_length =  len(x_batch_train) #num elements in each batch\n","                reconstruction, prediction = model(x_batch_train)\n","            \n","                # avg loss for each batch\n","                recon_loss =  self.custom_loss(y_batch_train, reconstruction)\n","                # predict_loss =  custom_loss(y_batch_train[1:,:], predictions)\n","\n","                # total avg loss for each batch\n","                total = self.tot_loss(model, recon_loss)\n","                total_loss_batch.append(total)\n","\n","            grads = tape.gradient(total, variables)\n","            optimizer.apply_gradients(zip(grads, variables))\n","            return total\n","\n","        def run_val_step(x_batch_val,y_batch_val):\n","            reconstruction_val, pred_val = model(x_batch_val)\n","            recon_loss = self.custom_loss(y_batch_val, reconstruction_val)\n","            total = self.tot_loss(model, recon_loss)\n","            print(\"total val loss:\", total)\n","            epoch_loss_metric.update_state(total)\n","        \n","        for callback in callbacks:\n","            callback.model = model\n","        \n","        best_epoch_val_loss = float(\"inf\")\n","        \n","        total_loss = [] # total loss for each epoch\n","        for epoch in range(epochs):\n","            total_loss_batch = [] # ttal loss for each batch \n","            #reconstruction_loss_batch = []\n","            #prediction_loss_batch = []\n","            \n","            print(\"\\nStart of epoch %d\" % (epoch,))\n","            start_time = time.time()\n","\n","            # Iterate over the train batches of the dataset.\n","            for step, (x_batch_train, y_batch_train) in enumerate(train_ds):\n","                train_total = run_train_step(x_batch_train, y_batch_train)\n","                \n","                # Log every 100 batches.\n","                if step % 100 == 0:\n","                    print(\n","                        \"Training loss (for one batch) at step %d: %.4f\"\n","                        % (step, float(train_total))\n","                    )\n","                    print(\"Seen so far: %s samples\" % ((step + 1) * batch_size))\n","            \n","            # outside batch loop\n","            total_loss_avg = np.sum(total_loss_batch)/num_batches\n","            total_loss.append(total_loss_avg)\n","\n","            print(\n","                    \"Average trainig loss at epoch %d: %.4f\"\n","                    % (epoch, float(total_loss_avg))\n","                )\n","            print(\"Time taken: %.2fs\" % (time.time() - start_time))\n","\n","        \n","            for step, (x_batch_val, y_batch_val) in enumerate(validation_data):\n","                run_val_step(x_batch_val, y_batch_val)\n","\n","            # Calling the callbacks after epoch\n","            epoch_loss_val = float(epoch_loss_metric.result().numpy())\n","            for callback in callbacks:\n","                # The \"my_metric\" is the objective passed to the tuner\n","                callback.on_epoch_end(epoch, logs={\"my_metric\": epoch_loss_val})\n","            epoch_loss_metric.reset_states()\n","\n","            print(f\"Epoch val loss: {epoch_loss_val}\")\n","            best_epoch_val_loss = min(best_epoch_val_loss, epoch_loss_val)\n","        \n","        # Return the evaluation metric value\n","        return best_epoch_val_loss"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["inner function length: 100\n","outer function length 0\n","outer function length [100]\n"]}],"source":["def outer_fun():\n","    length = 0\n","    outer_length = []\n","    def inner_fun():\n","        length = 100\n","        outer_length.append(length)\n","        print(\"inner function length:\",length)\n","\n","    inner_fun()\n","    print(\"outer function length\", length)\n","    print(\"outer function length\", outer_length)\n","    \n","outer_fun()"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[],"source":["tuner = kt.RandomSearch(\n","    objective=kt.Objective(\"my_metric\", \"min\"),\n","    max_trials=2,\n","    hypermodel=MyHyperModel(),\n","    directory=\"results\",\n","    project_name=\"custom_training\",\n","    overwrite=True,\n",")"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Trial 2 Complete [00h 00m 10s]\n","my_metric: 0.6526700258255005\n","\n","Best my_metric So Far: 0.506554365158081\n","Total elapsed time: 00h 00m 21s\n","INFO:tensorflow:Oracle triggered exit\n"]}],"source":["tuner.search(x=x_train, y=y_train, validation_data=train_dataset)"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{'learning_rate': 0.001}\n","Model: \"Deep_Koopman_Autoencoder\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 2)]          0                                            \n","__________________________________________________________________________________________________\n","encoder_layer (EncoderLayer)    (None, 16)           48          input_1[0][0]                    \n","__________________________________________________________________________________________________\n","tf.nn.elu (TFOpLambda)          (None, 16)           0           encoder_layer[0][0]              \n","__________________________________________________________________________________________________\n","encoder_layer_1 (EncoderLayer)  (None, 32)           544         tf.nn.elu[0][0]                  \n","__________________________________________________________________________________________________\n","tf.nn.elu_1 (TFOpLambda)        (None, 32)           0           encoder_layer_1[0][0]            \n","__________________________________________________________________________________________________\n","encoder_layer_2 (EncoderLayer)  (None, 64)           2112        tf.nn.elu_1[0][0]                \n","__________________________________________________________________________________________________\n","tf.nn.elu_2 (TFOpLambda)        (None, 64)           0           encoder_layer_2[0][0]            \n","__________________________________________________________________________________________________\n","koopman_layer (KoopmanLayer)    ((None, 64), (500, 6 0           tf.nn.elu_2[0][0]                \n","__________________________________________________________________________________________________\n","decoder_layer (DecoderLayer)    ((None, 32), (500, 3 2080        koopman_layer[0][0]              \n","                                                                 koopman_layer[0][1]              \n","__________________________________________________________________________________________________\n","tf.nn.elu_3 (TFOpLambda)        (None, 32)           0           decoder_layer[0][0]              \n","__________________________________________________________________________________________________\n","tf.nn.elu_4 (TFOpLambda)        (500, 32)            0           decoder_layer[0][1]              \n","__________________________________________________________________________________________________\n","decoder_layer_1 (DecoderLayer)  ((None, 16), (500, 1 528         tf.nn.elu_3[0][0]                \n","                                                                 tf.nn.elu_4[0][0]                \n","__________________________________________________________________________________________________\n","tf.nn.elu_5 (TFOpLambda)        (None, 16)           0           decoder_layer_1[0][0]            \n","__________________________________________________________________________________________________\n","tf.nn.elu_6 (TFOpLambda)        (500, 16)            0           decoder_layer_1[0][1]            \n","__________________________________________________________________________________________________\n","decoder_layer_2 (DecoderLayer)  ((None, 2), (500, 2) 34          tf.nn.elu_5[0][0]                \n","                                                                 tf.nn.elu_6[0][0]                \n","==================================================================================================\n","Total params: 5,346\n","Trainable params: 5,346\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["best_hps = tuner.get_best_hyperparameters()[0]\n","print(best_hps.values)\n","\n","best_model = tuner.get_best_models()[0]\n","best_model.summary()"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","INFO:tensorflow:Assets written to: checkpoints/test_koopman_1\\assets\n"]}],"source":["best_model.save('checkpoints/test_koopman_1')"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"Deep_Koopman_Autoencoder\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 2)]          0                                            \n","__________________________________________________________________________________________________\n","encoder_layer (EncoderLayer)    (None, 16)           48          input_1[0][0]                    \n","__________________________________________________________________________________________________\n","tf.nn.elu (TFOpLambda)          (None, 16)           0           encoder_layer[0][0]              \n","__________________________________________________________________________________________________\n","encoder_layer_1 (EncoderLayer)  (None, 32)           544         tf.nn.elu[0][0]                  \n","__________________________________________________________________________________________________\n","tf.nn.elu_1 (TFOpLambda)        (None, 32)           0           encoder_layer_1[0][0]            \n","__________________________________________________________________________________________________\n","encoder_layer_2 (EncoderLayer)  (None, 64)           2112        tf.nn.elu_1[0][0]                \n","__________________________________________________________________________________________________\n","tf.nn.elu_2 (TFOpLambda)        (None, 64)           0           encoder_layer_2[0][0]            \n","__________________________________________________________________________________________________\n","koopman_layer (KoopmanLayer)    ((None, 64), (500, 6 0           tf.nn.elu_2[0][0]                \n","__________________________________________________________________________________________________\n","decoder_layer (DecoderLayer)    ((None, 32), (500, 3 2080        koopman_layer[0][0]              \n","                                                                 koopman_layer[0][1]              \n","__________________________________________________________________________________________________\n","tf.nn.elu_3 (TFOpLambda)        (None, 32)           0           decoder_layer[0][0]              \n","__________________________________________________________________________________________________\n","tf.nn.elu_4 (TFOpLambda)        (500, 32)            0           decoder_layer[0][1]              \n","__________________________________________________________________________________________________\n","decoder_layer_1 (DecoderLayer)  ((None, 16), (500, 1 528         tf.nn.elu_3[0][0]                \n","                                                                 tf.nn.elu_4[0][0]                \n","__________________________________________________________________________________________________\n","tf.nn.elu_5 (TFOpLambda)        (None, 16)           0           decoder_layer_1[0][0]            \n","__________________________________________________________________________________________________\n","tf.nn.elu_6 (TFOpLambda)        (500, 16)            0           decoder_layer_1[0][1]            \n","__________________________________________________________________________________________________\n","decoder_layer_2 (DecoderLayer)  ((None, 2), (500, 2) 34          tf.nn.elu_5[0][0]                \n","                                                                 tf.nn.elu_6[0][0]                \n","==================================================================================================\n","Total params: 5,346\n","Trainable params: 5,346\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["new_model = tf.keras.models.load_model('checkpoints/test_koopman_1', compile=False)\n","new_model.summary() "]}],"metadata":{"colab":{"collapsed_sections":[],"name":"saveExample.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}
