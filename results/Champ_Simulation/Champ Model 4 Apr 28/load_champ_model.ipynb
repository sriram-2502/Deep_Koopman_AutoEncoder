{"cells":[{"cell_type":"markdown","metadata":{"id":"hrXv0rU9sIma"},"source":["# Implement a custom Autoencoder with Koopman layer"]},{"cell_type":"markdown","metadata":{},"source":["This code is to load a model (only)"]},{"cell_type":"markdown","metadata":{},"source":["## Version Control"]},{"cell_type":"markdown","metadata":{},"source":["To Do:\n","1) Account for trailing batch - Make robust (fixed issue by reshaping input data)\n","2) Preprocess Data\n","3) Make sure sim data is different for different ground parameters\n","4) Validation data has different batch size. Address when HP training\n","5) Address semi graident issue for K^m*z in linearity loss (Prob fine)"]},{"cell_type":"markdown","metadata":{"id":"3LXMVuV0VhDr"},"source":["## Setup"]},{"cell_type":"code","execution_count":217,"metadata":{"execution":{"iopub.execute_input":"2022-02-26T02:24:32.808146Z","iopub.status.busy":"2022-02-26T02:24:32.807594Z","iopub.status.idle":"2022-02-26T02:24:35.841571Z","shell.execute_reply":"2022-02-26T02:24:35.840833Z"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1649697591026,"user":{"displayName":"Sri Ram","userId":"08645352860667302995"},"user_tz":240},"id":"NiolgWMPgpwI"},"outputs":[],"source":["import tensorflow as tf\n","import matplotlib as mpl\n","from matplotlib import pyplot as plt\n","from tensorflow import keras\n","\n","import  numpy as np\n","import pandas as pd\n","\n","\n","import matplotlib.colors as mcol\n","import matplotlib as mpl\n","from matplotlib import pyplot as plt\n","import matplotlib.animation as animation\n","\n","\n","import time \n","import os\n","\n","import glob"]},{"cell_type":"code","execution_count":218,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1649697591026,"user":{"displayName":"Sri Ram","userId":"08645352860667302995"},"user_tz":240},"id":"Iqo002C_dKA-"},"outputs":[],"source":["plt.rcParams['figure.figsize'] = [9, 6]\n","colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"]},{"cell_type":"code","execution_count":219,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":779,"status":"ok","timestamp":1649697592846,"user":{"displayName":"Sri Ram","userId":"08645352860667302995"},"user_tz":240},"id":"gjzUWH8FdO-d","outputId":"29a19841-26b1-4ec4-96ee-1a44e74e40c7"},"outputs":[],"source":["#from google.colab import drive\n","#drive.mount('/gdrive')"]},{"cell_type":"markdown","metadata":{},"source":["Comment out if don't need"]},{"cell_type":"code","execution_count":220,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1 Physical GPUs, 1 Logical GPUs\n"]}],"source":["gpus = tf.config.experimental.list_physical_devices('GPU')\n","if gpus:\n","    try:\n","        # Currently, memory growth needs to be the same across GPUs\n","        for gpu in gpus:\n","            tf.config.experimental.set_memory_growth(gpu, True)\n","        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n","        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n","    except RuntimeError as e:\n","        # Memory growth must be set before GPUs have been initialized\n","        print(e)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Load the Model"]},{"cell_type":"code","execution_count":222,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"Koopman_AE_Model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","encoder_model_2 (EncoderMode multiple                  8464      \n","_________________________________________________________________\n","koopman__model_2 (Koopman_Mo multiple                  256       \n","_________________________________________________________________\n","decoder_model_2 (DecoderMode multiple                  9635      \n","=================================================================\n","Total params: 18,355\n","Trainable params: 18,355\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["new_model = tf.keras.models.load_model('checkpoints/champ_Trained_Model', compile=False)\n","new_model.summary()"]},{"cell_type":"markdown","metadata":{},"source":["## Load data"]},{"cell_type":"markdown","metadata":{},"source":["### Read Sim Data Functions"]},{"cell_type":"code","execution_count":223,"metadata":{},"outputs":[],"source":["def preprocessSimData(df, desiredStates:list, initialIndex:int=300, finalIndex:int=812):\n","    '''\n","    Preprocess text file (fixing formatting issue in data as well) while returning a dataframe object with the desired states selected\n","\n","    Parameters:\n","    -----------\n","    df: dataFrame\n","        Panda dataframe that is read from one of the recorded simulation .txt files\n","    desiredStates: list\n","        List of desired states to return as a panda dataframe object in sequential order\n","\n","    Return:\n","    ----------\n","    stateMatrix: dataFrame\n","        State matrix with desired states\n","    '''\n","\n","\n","\n","    # Fix formatting Variables\n","    falseList = ['time_lf_hip_joint_position', 'lf_lower_leg_joint_position', 'lf_upper_leg_joint_position', 'lh_hip_joint_position', 'lh_lower_leg_joint_position', 'lh_upper_leg_joint_position',\n","                'rf_hip_joint_position', 'rf_lower_leg_joint_position', 'rf_upper_leg_joint_position', 'rh_hip_joint_position', 'rh_lower_leg_joint_position', 'rh_upper_leg_joint_position',\n","                'lf_hip_joint_vel', 'lf_lower_leg_joint_vel', 'lf_upper_leg_joint_vel', 'lh_hip_joint_vel', 'lh_lower_leg_joint_vel', 'lh_upper_leg_joint_vel',\n","                'rf_hip_joint_vel', 'rf_lower_leg_joint_vel', 'rf_upper_leg_joint_vel', 'rh_hip_joint_vel', 'rh_lower_leg_joint_vel', 'rh_upper_leg_joint_vel',\n","                'lf_hip_joint_effort', 'lf_lower_leg_joint_effort', 'lf_upper_leg_joint_effort', 'lh_hip_joint_effort', 'lh_lower_leg_joint_effort', 'lh_upper_leg_joint_effort',\n","                'rf_hip_joint_effort', 'rf_lower_leg_joint_effort', 'rf_upper_leg_joint_effort', 'rh_hip_joint_effort', 'rh_lower_leg_joint_effort', 'rh_upper_leg_joint_effort', 'nan']\n","    df.columns = falseList\n","    df['time_lf_hip_joint_position'] = df.time_lf_hip_joint_position.str[0:8] + ' ' + df.time_lf_hip_joint_position.str[8:]\n","\n","\n","    # Data and State Name List\n","    data = df.values # np array of data values\n","    namesList = ['time', 'lf_hip_joint_position', 'lf_lower_leg_joint_position', 'lf_upper_leg_joint_position', 'lh_hip_joint_position', 'lh_lower_leg_joint_position', 'lh_upper_leg_joint_position',\n","                'rf_hip_joint_position', 'rf_lower_leg_joint_position', 'rf_upper_leg_joint_position', 'rh_hip_joint_position', 'rh_lower_leg_joint_position', 'rh_upper_leg_joint_position',\n","                'lf_hip_joint_vel', 'lf_lower_leg_joint_vel', 'lf_upper_leg_joint_vel', 'lh_hip_joint_vel', 'lh_lower_leg_joint_vel', 'lh_upper_leg_joint_vel',\n","                'rf_hip_joint_vel', 'rf_lower_leg_joint_vel', 'rf_upper_leg_joint_vel', 'rh_hip_joint_vel', 'rh_lower_leg_joint_vel', 'rh_upper_leg_joint_vel',\n","                'lf_hip_joint_effort', 'lf_lower_leg_joint_effort', 'lf_upper_leg_joint_effort', 'lh_hip_joint_effort', 'lh_lower_leg_joint_effort', 'lh_upper_leg_joint_effort',\n","                'rf_hip_joint_effort', 'rf_lower_leg_joint_effort', 'rf_upper_leg_joint_effort', 'rh_hip_joint_effort', 'rh_lower_leg_joint_effort', 'rh_upper_leg_joint_effort']\n","\n","    dictStates = {}\n","    staticCounter = 0 # Variable to account for formatting issue\n","    for index in range(len(namesList)-1):\n","        if index == 0 and staticCounter == 0: # Condition for formatting issue of collected data\n","            for j in range(len(data[:,index])): # Looping through all elements in column 0 and converting to float\n","                if j == 0: # Initialize array\n","                    array1 = float(data[j,index][0:8])\n","                    #print(array1)\n","                    array2 = float(data[j,index][8:])\n","                    #print(array2)\n","                else:\n","                    array1 = np.vstack((array1,float(data[j,index][0:8])))\n","                    array2 = np.vstack((array2,float(data[j,index][8:])))\n","            dictStates[namesList[index]] = np.squeeze(array1[initialIndex:finalIndex])\n","            dictStates[namesList[index+1]] = np.squeeze(array2[initialIndex:finalIndex])        \n","        else:\n","            dictStates[namesList[index+1]] = data[initialIndex:finalIndex,index]\n","    for counter, names in enumerate(desiredStates):\n","        if counter == 0:\n","            stateMatrix = np.reshape(dictStates[names], (-1,1))\n","        else:\n","            stateMatrix = np.hstack((stateMatrix, np.reshape(dictStates[names], (-1,1))))\n","    return pd.DataFrame(stateMatrix, columns = desiredStates)\n","\n","\n","\n","def preprocessFile(fileNames:list, initialIndex:int, finalIndex:int, desiredStates:list):\n","    '''\n","    Given fileNames to read, reads the file(s) and returns all data concatenated in a panda dataframe framework\n","\n","    Paramaters:\n","    -----------\n","    fileNamess:list\n","        List of filenames to read and concatenate data together\n","    intialIndex: int\n","        Index to start reading each file's data from\n","    finalIndex: int\n","        Index to stop reading each file's data from\n","    desiredStates:list\n","        List of states to read\n","    \n","    Return:\n","    ----------\n","    totalData: dataFrame\n","        Returns data of all filenames with given states in one panda dataframe\n","    '''\n","\n","    filePaths = []\n","    for i in fileNames:\n","        filePaths.append(glob.glob(i))\n","    #print(filePaths)\n","\n","\n","    dataFrameList = []\n","    for i in filePaths:\n","        for j in i:\n","            df = pd.read_csv(j, sep= \" \", header=None)\n","            dataFrameList.append(preprocessSimData(df, desiredStates, initialIndex=initialIndex, finalIndex=finalIndex)) # 712-200 = 512 --> 512-1 is 512 indices (i.e. [0, 511])\n","\n","    totalData = pd.concat(dataFrameList)\n","    return totalData"]},{"cell_type":"markdown","metadata":{},"source":["### Read full data"]},{"cell_type":"code","execution_count":224,"metadata":{},"outputs":[],"source":["# List of states\n","namesList = ['time', 'lf_hip_joint_position', 'lf_lower_leg_joint_position', 'lf_upper_leg_joint_position', 'lh_hip_joint_position', 'lh_lower_leg_joint_position', 'lh_upper_leg_joint_position',\n","                'rf_hip_joint_position', 'rf_lower_leg_joint_position', 'rf_upper_leg_joint_position', 'rh_hip_joint_position', 'rh_lower_leg_joint_position', 'rh_upper_leg_joint_position',\n","                'lf_hip_joint_vel', 'lf_lower_leg_joint_vel', 'lf_upper_leg_joint_vel', 'lh_hip_joint_vel', 'lh_lower_leg_joint_vel', 'lh_upper_leg_joint_vel',\n","                'rf_hip_joint_vel', 'rf_lower_leg_joint_vel', 'rf_upper_leg_joint_vel', 'rh_hip_joint_vel', 'rh_lower_leg_joint_vel', 'rh_upper_leg_joint_vel',\n","                'lf_hip_joint_effort', 'lf_lower_leg_joint_effort', 'lf_upper_leg_joint_effort', 'lh_hip_joint_effort', 'lh_lower_leg_joint_effort', 'lh_upper_leg_joint_effort',\n","                'rf_hip_joint_effort', 'rf_lower_leg_joint_effort', 'rf_upper_leg_joint_effort', 'rh_hip_joint_effort', 'rh_lower_leg_joint_effort', 'rh_upper_leg_joint_effort']\n"]},{"cell_type":"code","execution_count":225,"metadata":{},"outputs":[],"source":["desiredStates = ['lf_hip_joint_position', 'lf_hip_joint_vel',  'lf_hip_joint_effort']\n","\n","input_dim = len(desiredStates)\n","output_dim = input_dim\n","\n","trajLength = 2**7 # Length of each trajectory in the dataset\n","\n","filePath = \"simData\"\n","fileNames = [filePath + '/plane_kp_100e10_kd_0/joint_state_test_plane_kp_100e10_kd_0_forward_0.1*']\n","\n","\n","numTraj = 4 # Total number of trajectories in the dataset (train)\n","numTraj_val = 1\n","batch_size = int(2**7) # Number of snapshots in each batch\n","numTraj_batch = int(batch_size/trajLength)\n","\n","\n","initialIndex, finalIndex= 200, 200+trajLength*(numTraj+numTraj_val)\n","\n","num_batches_train = int(trajLength*numTraj/batch_size) ## num_batches = trajLength*numTraj/batch_size \n","num_batches_val = int(trajLength*numTraj_val/batch_size)\n"]},{"cell_type":"code","execution_count":226,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>lf_hip_joint_position</th>\n","      <th>lf_hip_joint_vel</th>\n","      <th>lf_hip_joint_effort</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-0.0005</td>\n","      <td>0.0852</td>\n","      <td>0.107</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.0004</td>\n","      <td>0.0631</td>\n","      <td>0.0889</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.0004</td>\n","      <td>0.0054</td>\n","      <td>0.086</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.0004</td>\n","      <td>0.0151</td>\n","      <td>0.0593</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.0003</td>\n","      <td>0.0099</td>\n","      <td>0.0539</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  lf_hip_joint_position lf_hip_joint_vel lf_hip_joint_effort\n","0               -0.0005           0.0852               0.107\n","1               -0.0004           0.0631              0.0889\n","2               -0.0004           0.0054               0.086\n","3               -0.0004           0.0151              0.0593\n","4               -0.0003           0.0099              0.0539"]},"execution_count":226,"metadata":{},"output_type":"execute_result"}],"source":["doggoFrame = preprocessFile(fileNames,initialIndex,finalIndex, desiredStates)\n","doggoFrame.head(5)"]},{"cell_type":"code","execution_count":227,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Datapoints:  640\n"]}],"source":["print(\"Datapoints: \", len(doggoFrame.index))"]},{"cell_type":"code","execution_count":228,"metadata":{"executionInfo":{"elapsed":395,"status":"ok","timestamp":1649697594571,"user":{"displayName":"Sri Ram","userId":"08645352860667302995"},"user_tz":240},"id":"mbf4rGRodKBA"},"outputs":[],"source":["doggo_train = doggoFrame.values[:numTraj*trajLength,:]\n","doggo_validation = doggoFrame.values[numTraj*trajLength:(numTraj+numTraj_val)*trajLength,:]\n","doggo_test = doggoFrame.values[(numTraj+numTraj_val)*trajLength:,:]\n","\n","doggo_train = np.asarray(doggo_train).astype('float32')\n","doggo_test = np.asarray(doggo_test).astype('float32')\n","doggo_validation = np.asarray(doggo_validation).astype('float32')"]},{"cell_type":"code","execution_count":229,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Size of doggo_train: 512\n","Size of doggo_validation: 128\n","Size of doggo_test: 0\n"]}],"source":["print(\"Size of doggo_train:\", len(doggo_train))\n","print(\"Size of doggo_validation:\", len(doggo_validation))\n","print(\"Size of doggo_test:\", len(doggo_test))"]},{"cell_type":"markdown","metadata":{},"source":["### Make into dataset"]},{"cell_type":"code","execution_count":230,"metadata":{"executionInfo":{"elapsed":227,"status":"ok","timestamp":1649697595911,"user":{"displayName":"Sri Ram","userId":"08645352860667302995"},"user_tz":240},"id":"oC-2Gx9KdKBB"},"outputs":[],"source":["# Normalize the data\n","min_val = tf.reduce_min(doggo_train)\n","max_val = tf.reduce_max(doggo_train)\n","\n","doggo_train = (doggo_train - min_val) / (max_val - min_val)\n","doggo_validation = (doggo_validation - min_val) / (max_val - min_val)\n","doggo_test = (doggo_test - min_val) / (max_val - min_val)\n","\n","train_data = tf.cast(doggo_train[0:batch_size*num_batches_train], tf.float32)\n","validation_data = tf.cast(doggo_validation[0:batch_size*num_batches_val], tf.float32)\n","validation_data = tf.data.Dataset.from_tensor_slices((validation_data, validation_data)).batch(batch_size)\n","test_data = tf.cast(doggo_test, tf.float32)"]},{"cell_type":"code","execution_count":231,"metadata":{},"outputs":[],"source":["x_train = train_data\n","y_train = train_data"]},{"cell_type":"markdown","metadata":{},"source":["# Animate Setup"]},{"cell_type":"code","execution_count":232,"metadata":{},"outputs":[],"source":["Writer = animation.writers['ffmpeg']\n","writer = Writer(fps=20, metadata=dict(artist='Me'), bitrate=1800)"]},{"cell_type":"code","execution_count":233,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["17\n"]}],"source":["mp4FilePath = 'mp4/'\n","try:\n","    os.mkdir(mp4FilePath)\n","except OSError as exc:\n","    print(exc.errno)"]},{"cell_type":"code","execution_count":234,"metadata":{},"outputs":[],"source":["def animateStates(predictedLine, gTruthLine, label1, label2, desiredStates:list, titlePrefix, mp4FilePath = 'mp4/'):\n","    '''\n","    Given the predicted and ground truth trajectory, as well as desired states,\n","    animate the trajectory with given legend into a mp4 under the mp4FilePath folder\n","\n","    Parameters:\n","    -----------\n","    predictedLine: ndarray\n","        Trajectory of the predicted line (nxlen(desiredStates))\n","    gTruthLine: ndarray\n","        Trajectory of the ground truth line (+/- stdDev)\n","    label1: str\n","        Label for predicted line (suffix)\n","    label2: str\n","        Label for ground truth line (suffix)\n","    desiredStates: list\n","        List of the desired states\n","    titlePrefix: str\n","        Prefix title to save into mp4FilePath\n","    mp4FilePath: str\n","        Directory path to save mp4\n","    ifBoundLine: Boolean\n","        ifBoundLine is true, graphs with bounded fill between lines, else just graphs middle line\n","\n","    Return:\n","    ---------\n","    None\n","    '''\n","    for j in range(np.shape(predictedLine)[1]):\n","        # Set up figure, axis, and plot element want to animate\n","        fig, ax = plt.subplots(figsize=(10,6))\n","        ax.set_xlim([0, 128])\n","        ax.set_ylim([0, 1])\n","        line, = ax.plot([],[], lw=1, label=desiredStates[j].replace(\"_\", \" \") + \" \" + label1)\n","        line.set_color('#1f77b4')\n","        line2, = ax.plot([],[], lw=1, label=desiredStates[j].replace(\"_\", \" \") + \" \" + label2)\n","        line2.set_color('black')\n","        \n","        plt.style.use('default')\n","        plt.setp(line2, linestyle='--')\n","        plt.legend()\n","        plt.tight_layout()\n","\n","        # Initialize function: plot the background of each frame\n","        def init():\n","            line.set_data([], [])\n","            line2.set_data([],[])\n","            return line,\n","\n","\n","        # animation function called sequentially\n","        def animate(i, j):\n","            x = range(len(predictedLine[0:i,j]))\n","            data = predictedLine[0:i,j] #select data range\n","            line.set_data(x,data)\n","\n","            line2.set_data(x, gTruthLine[0:i,j])\n","          \n","            return line,\n","\n","        anim = animation.FuncAnimation(fig, animate, init_func=init, frames=128,\n","                                    interval=10, repeat=True, blit=True, fargs=(j,))\n","\n","        anim.save(mp4FilePath+titlePrefix+'_'+ desiredStates[j]+'.mp4', writer=writer, dpi=300)\n","        plt.close()"]},{"cell_type":"code","execution_count":235,"metadata":{},"outputs":[],"source":["def animateStatesError(middleLine, boundLine, desiredStates:list, titlePrefix, mp4FilePath = 'mp4/', ifBoundLine=True):\n","    '''\n","    Given the average trajectory error, standard deviation error, and desired states,\n","    animate the trajectory with given legend into a mp4 under the mp4 folder\n","\n","    Parameters:\n","    -----------\n","    middleLine: ndarray\n","        Trajectory of the middle line (nxlen(desiredStates))\n","    boundLine: ndarray\n","        Trajectory of the bound for upper and lower bound (+/- stdDev)\n","    desiredStates: list\n","        List of the desired states\n","    titlePrefix: str\n","        Prefix title to save into mp4FilePath\n","    mp4FilePath: str\n","        Directory path to save mp4\n","    ifBoundLine: Boolean\n","        ifBoundLine is true, graphs with bounded fill between lines, else just graphs middle line\n","\n","    Return:\n","    ---------\n","    None\n","    '''\n","    for j in range(np.shape(middleLine)[1]):\n","        # Set up figure, axis, and plot element want to animate\n","        fig, ax = plt.subplots(figsize=(10,6))\n","        ax.set_xlim([0, 128])\n","        ax.set_ylim([0, 1])\n","        line, = ax.plot([],[], lw=1, label=desiredStates[j].replace(\"_\", \" \"))\n","        plt.style.use('default')\n","        plt.legend()\n","        plt.tight_layout()\n","\n","        # Initialize function: plot the background of each frame\n","        def init():\n","            line.set_data([], [])\n","\n","            return line,\n","\n","\n","        # animation function called sequentially\n","        def animate(i, j):\n","            x = range(len(middleLine[0:i,j]))\n","            data = middleLine[0:i,j] #select data range\n","            line.set_data(x,data)\n","            line.set_color('#1f77b4')\n","        \n","            if ifBoundLine:\n","                p = plt.fill_between(range(len(boundLine[0:i,j])), middleLine[0:i,j]-boundLine[0:i,j], \n","                                middleLine[0:i,j]+boundLine[0:i,j], facecolor='lightsteelblue')\n","                return line, p,\n","            else:\n","                return line,\n","\n","        anim = animation.FuncAnimation(fig, animate, init_func=init, frames=128,\n","                                    interval=10, repeat=True, blit=True, fargs=(j,))\n","\n","        anim.save(mp4FilePath+titlePrefix+'_'+ desiredStates[j]+'.mp4', writer=writer, dpi=300)\n","        plt.close()"]},{"cell_type":"markdown","metadata":{},"source":["# Load data into model"]},{"cell_type":"code","execution_count":236,"metadata":{},"outputs":[],"source":["input = x_train\n","new_out1, new_out2, new_out3 = new_model(input)"]},{"cell_type":"markdown","metadata":{},"source":["# Graphing Error Section"]},{"cell_type":"markdown","metadata":{},"source":["#### Average Error Function"]},{"cell_type":"code","execution_count":237,"metadata":{},"outputs":[],"source":["def preProcessForAvg(input, numTraj_batch, trajLength, num_batches, desiredStates, model):\n","    '''\n","    Given input, the number of trajectory in each batch, and the trajector length, outputs\n","    batch data concatenated vertically on top of one another by calling the Koopman AE class\n","\n","    Parameters:\n","    -----------\n","    input: Tensor\n","        Input data to reshape into outputs\n","    numTraj_batch: int\n","        Number of trajectory per batch\n","    trajLength: int\n","        Number of snapshots in a trajectory\n","    desiredStates: list\n","        List of states\n","    model: Koopman AE keras model\n","        Koopman AE model to propagate data\n","\n","    Return:\n","    ----------\n","    x1_all: tensor\n","        Copy of input (No need for change) (Ground Truth)\n","    x2_all: tensor\n","        Concatenated tensor of 1 time shifted data for all batches (Ground Truth)\n","    x3_all: tensor\n","        Concatenated tensor of 1 time step shifted data for all batches (x2_all=x3_all) (Ground Truth)\n","    out1_all: tensor\n","        Reconstruction of input (parameter) using the Koopman AE class\n","    out2_all: tensor\n","        Predicted output from Koopman model of concatenated tensors of 1 time shifted data for all batches\n","    out3_all: tensor\n","        Predicted n time step output from Koopman model of concatenated tensors data for all batches\n","    '''\n","    \n","    x2_all = []\n","    out1_all = []\n","    out2_all = []\n","    out3_all = []\n","    x = input\n","    #print(\"Input shape\", tf.shape(x))\n","    for i in range(num_batches):\n","        x2 = []\n","        for j in range(numTraj_batch):\n","            x2.append(x[(i*numTraj_batch+j)*trajLength+1:(i*numTraj_batch+j+1)*trajLength])\n","        x2 = tf.reshape(x2, [-1, x.shape[-1]]) # Shifted input for a batch\n","        x2_all.append(x2)\n","        \n","        x_input = x[i*numTraj_batch*trajLength:(i*numTraj_batch+1)*trajLength]\n","        #print(tf.shape(x_input))\n","        out1, out2, out3 = model(x_input)\n","        out1_all.append(out1)\n","        out2_all.append(out2)\n","        out3_all.append(out3)\n","        \n","    x1_all = x\n","    x2_all = tf.reshape(x2_all,(-1,len(desiredStates)))\n","    x3_all = x2_all\n","    out1_all = tf.reshape(out1_all,(-1,len(desiredStates)))\n","    out2_all = tf.reshape(out2_all,(-1,len(desiredStates)))\n","    out3_all = tf.reshape(out3_all,(-1,len(desiredStates)))\n","\n","    '''\n","    print(tf.shape(x2_all))\n","    print(tf.shape(out1_all))\n","    print(tf.shape(out2_all))\n","    print(tf.shape(out3_all))\n","    '''\n","\n","    return x1_all, x2_all, x3_all, out1_all, out2_all, out3_all"]},{"cell_type":"code","execution_count":276,"metadata":{},"outputs":[],"source":["def avgTrajError(gTruth, predicted, trajLength, numTraj):\n","    '''\n","    Get the average trajectory error with min and max values (Maybe std dev better)\n","\n","    Parameters:\n","    -----------\n","    gTruth: tensor or ndarray\n","        Ground Truth matrix\n","    predicted: tensor or ndarray\n","        Predicted matrix\n","    trajLength: int\n","        Length of trajectory\n","    numTraj: int\n","        Number of trajectory (total?)\n","    \n","\n","    Return:\n","    ----------\n","    avgErrorList: list\n","        List of average errors of all trajectories (each index is the avg error of the states at a point of time along the trajectory)\n","    \n","    errorList: list\n","        List of error of all states and trajectory\n","    '''\n","    errorList = []\n","    avgErrorList = []\n","    numStates = len(gTruth[0,:])\n","    for i in range(numTraj):\n","        '''\n","        print(\"Gtruth\")\n","        print(np.array(gTruth)[i*trajLength:(i+1)*trajLength,:])\n","        print(\"Predicted\")\n","        print(np.array(predicted[i*trajLength:(i+1)*trajLength,:]))\n","        print(\"---Loop---\")\n","        '''\n","        errorList.append(np.array(gTruth)[i*trajLength:(i+1)*trajLength,:] - np.array(predicted[i*trajLength:(i+1)*trajLength,:]))\n","    \n","    #print(\"Error List\")\n","    #print(np.shape(errorList[0]))\n","    \n","    for j in range(trajLength):\n","        #print(\"Length of Traj %d\"% j)\n","        for k in range(numTraj):\n","            #print(\"Traj: %d\"% k)\n","            if k == 0:\n","                avgErrorList.append(errorList[k][j,:])\n","            else:\n","                #print(avgErrorList[j])\n","                avgErrorList[j] = (k*avgErrorList[j]+errorList[k][j,:])/(k+1) # Recursive average formula\n","    return avgErrorList, errorList\n","        \n","    "]},{"cell_type":"markdown","metadata":{},"source":["#### Preprocess Error Graph Data"]},{"cell_type":"code","execution_count":239,"metadata":{},"outputs":[],"source":["x1_all,x2_all,x3_all, out1_all,out2_all,out3_all = preProcessForAvg(x_train,numTraj_batch, trajLength, num_batches_train, desiredStates, model=new_model)\n","avgTrajErrorList, errorList = avgTrajError(x3_all, out3_all, trajLength-1, numTraj)"]},{"cell_type":"code","execution_count":240,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["17\n"]}],"source":["saveErrorPath = 'errorGraph/'\n","try:\n","    os.mkdir(saveErrorPath)\n","except OSError as exc:\n","    print(exc.errno)"]},{"cell_type":"markdown","metadata":{},"source":["#### Error Graphs"]},{"cell_type":"markdown","metadata":{},"source":["##### Reconstruction Error"]},{"cell_type":"code","execution_count":241,"metadata":{},"outputs":[],"source":["avgTrajErrorList, errorList = avgTrajError(x1_all, out1_all, trajLength, numTraj)\n","avgTrajErrorArray = np.array(avgTrajErrorList)\n","errorArray = np.array(errorList)\n","errorStdDevArray = np.std(errorArray,axis=0)"]},{"cell_type":"code","execution_count":242,"metadata":{},"outputs":[],"source":["for i in range(len(desiredStates)):\n","    plt.figure()\n","    plt.style.use('default')\n","    plt.plot(avgTrajErrorArray[:,i])\n","    plt.fill_between(range(len(errorStdDevArray[:,i])), avgTrajErrorArray[:,i]-errorStdDevArray[:,i], avgTrajErrorArray[:,i]+errorStdDevArray[:,i],alpha = 0.3)\n","    title=desiredStates[i]\n","    plt.title(title)\n","    plt.ylabel(\"Reconstruction Error\")\n","    plt.xlabel(\"Time Step\")\n","    plt.ylim((0,1))\n","    plt.savefig(saveErrorPath+'recon_error_'+title+'.png', dpi=300)\n","    plt.close()"]},{"cell_type":"markdown","metadata":{},"source":["##### Forward Time Shift Prediction Error"]},{"cell_type":"markdown","metadata":{},"source":["##### Linearity Prediction Error"]},{"cell_type":"code","execution_count":243,"metadata":{},"outputs":[],"source":["avgTrajErrorList, errorList = avgTrajError(x2_all, out2_all, trajLength-1, numTraj)\n","avgTrajErrorArray = np.array(avgTrajErrorList)\n","errorArray = np.array(errorList)\n","errorStdDevArray = np.std(errorArray,axis=0)"]},{"cell_type":"code","execution_count":244,"metadata":{},"outputs":[],"source":["for i in range(len(desiredStates)):\n","    plt.figure()\n","    plt.style.use('default')\n","    plt.plot(avgTrajErrorArray[:,i])\n","    plt.fill_between(range(len(errorStdDevArray[:,i])), avgTrajErrorArray[:,i]-errorStdDevArray[:,i], avgTrajErrorArray[:,i]+errorStdDevArray[:,i],alpha = 0.3)\n","    title=desiredStates[i]\n","    plt.title(title)\n","    plt.ylabel(\"Forward Time Shift Prediction Error\")\n","    plt.xlabel(\"Time Step\")\n","    plt.ylim((0,1))\n","    plt.savefig(saveErrorPath+'ftimeShift_error_'+title+'.png', dpi=300)\n","    plt.close()"]},{"cell_type":"markdown","metadata":{},"source":["#### Reconstruction/Forward Time Shift Prediction/Linear Prediction Graph"]},{"cell_type":"code","execution_count":245,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["17\n"]}],"source":["saveOutputPath = 'outputGraph/'\n","try:\n","    os.mkdir(saveOutputPath)\n","except OSError as exc:\n","    print(exc.errno)"]},{"cell_type":"code","execution_count":246,"metadata":{},"outputs":[],"source":["for i in range(len(desiredStates)):\n","    plt.figure(figsize=(8,4))\n","    plt.style.use('default')\n","    plt.plot(x1_all[:,i])\n","    plt.plot(out1_all[:,i],'--',label=\"\")\n","    plt.ylabel(\"Reconstruction\")\n","    plt.xlabel(\"Time Step\")\n","    title = desiredStates[i]\n","    plt.title(title)\n","    plt.ylim((0,1))\n","    plt.savefig(saveOutputPath+'recon_'+title+'.png', dpi=300)\n","    plt.close()"]},{"cell_type":"code","execution_count":247,"metadata":{},"outputs":[],"source":["for i in range(len(desiredStates)):\n","    plt.figure(figsize=(8,4))\n","    plt.style.use('default')\n","    plt.plot(x2_all[:,i])\n","    plt.plot(out2_all[:,i],'--',label=\"\")\n","    plt.ylabel(\"Forward Time Shift Prediction\")\n","    plt.xlabel(\"Time Step\")\n","    title = desiredStates[i]\n","    plt.title(title)\n","    plt.ylim((0,1))\n","    plt.savefig(saveOutputPath+'ftimeShiftPred_'+title+'.png', dpi=300)\n","    plt.close()"]},{"cell_type":"code","execution_count":248,"metadata":{},"outputs":[],"source":["for i in range(len(desiredStates)):\n","    plt.figure(figsize=(8,4))\n","    plt.style.use('default')\n","    plt.plot(x3_all[:,i])\n","    plt.plot(out3_all[:,i],'--',label=\"\")\n","    plt.ylabel(\"Linear Prediction\")\n","    plt.xlabel(\"Time Step\")\n","    title = desiredStates[i]\n","    plt.title(title)\n","    plt.ylim((0,1))\n","    plt.savefig(saveOutputPath+'linPred_'+title+'.png', dpi=300)\n","    plt.close()"]},{"cell_type":"code","execution_count":249,"metadata":{},"outputs":[],"source":["x = input\n","x2 = []\n","for i in range(numTraj_batch):\n","    x2.append(x[i*trajLength+1:(i+1)*trajLength])\n","x2 = tf.reshape(x2, [-1, x.shape[-1]]) # Shifted input"]},{"cell_type":"code","execution_count":250,"metadata":{},"outputs":[],"source":["avgTrajErrorList, errorList = avgTrajError(x3_all, out3_all, trajLength-1, numTraj)\n","avgTrajErrorArray = np.array(avgTrajErrorList)\n","errorArray = np.array(errorList)\n","errorStdDevArray = np.std(errorArray,axis=0)"]},{"cell_type":"code","execution_count":251,"metadata":{},"outputs":[],"source":["for i in range(len(desiredStates)):\n","    plt.figure()\n","    plt.style.use('default')\n","    plt.plot(avgTrajErrorArray[:,i])\n","    plt.fill_between(range(len(errorStdDevArray[:,i])), avgTrajErrorArray[:,i]-errorStdDevArray[:,i], avgTrajErrorArray[:,i]+errorStdDevArray[:,i],alpha = 0.3)\n","    title=desiredStates[i]\n","    plt.title(title)\n","    plt.ylabel(\"Linear Prediction Error\")\n","    plt.xlabel(\"Time Step\")\n","    plt.ylim((0,1))\n","    plt.savefig(saveErrorPath+'linPred_'+title+'.png', dpi=300)\n","    plt.close()"]},{"cell_type":"markdown","metadata":{},"source":["# Animate"]},{"cell_type":"markdown","metadata":{},"source":["Error"]},{"cell_type":"code","execution_count":257,"metadata":{},"outputs":[],"source":["# Reconstruction Error\n","avgTrajErrorList, errorList = avgTrajError(x1_all, out1_all, trajLength, numTraj)\n","avgTrajErrorArray = np.array(avgTrajErrorList)\n","errorArray = np.array(errorList)\n","errorStdDevArray = np.std(errorArray,axis=0)\n","\n","animateStatesError(avgTrajErrorArray, errorStdDevArray, desiredStates, 'recon')\n","\n","# Forward Time Shift Prediction Error\n","avgTrajErrorList, errorList = avgTrajError(x2_all, out2_all, trajLength-1, numTraj)\n","avgTrajErrorArray = np.array(avgTrajErrorList)\n","errorArray = np.array(errorList)\n","errorStdDevArray = np.std(errorArray,axis=0)\n","\n","animateStatesError(avgTrajErrorArray, errorStdDevArray, desiredStates, 'fTimeShiftPred')\n","\n","# Linear Prediction Error\n","avgTrajErrorList, errorList = avgTrajError(x3_all, out3_all, trajLength-1, numTraj)\n","avgTrajErrorArray = np.array(avgTrajErrorList)\n","errorArray = np.array(errorList)\n","errorStdDevArray = np.std(errorArray,axis=0)\n","\n","animateStatesError(avgTrajErrorArray, errorStdDevArray, desiredStates, 'linPred')"]},{"cell_type":"markdown","metadata":{},"source":["Trajectory"]},{"cell_type":"code","execution_count":258,"metadata":{},"outputs":[],"source":["animateStates(out1_all,x1_all,'Reconstruction','Truth',  desiredStates, 'test_traj_recon')\n","animateStates(out2_all,x2_all,'Forward Time Shift','Truth', desiredStates, 'test_traj_FTimeShiftPred')\n","animateStates(out3_all,x3_all,'Lin Pred','Truth', desiredStates, 'test_traj_linPred')"]},{"cell_type":"markdown","metadata":{},"source":["# Test Graphs"]},{"cell_type":"code","execution_count":259,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["17\n"]}],"source":["saveTestOutputPath = 'testOutputGraph/'\n","try:\n","    os.mkdir(saveTestOutputPath)\n","except OSError as exc:\n","    print(exc.errno)"]},{"cell_type":"code","execution_count":260,"metadata":{},"outputs":[],"source":["input = doggo_validation\n","new_out1, new_out2, new_out3 = new_model(input)"]},{"cell_type":"code","execution_count":261,"metadata":{},"outputs":[],"source":["nx1_all,nx2_all,nx3_all,nout1_all,nout2_all,nout3_all = preProcessForAvg(input,1,128,num_batches_val,desiredStates, new_model)"]},{"cell_type":"code","execution_count":287,"metadata":{},"outputs":[],"source":["for i in range(len(desiredStates)):\n","    plt.figure(figsize=(8,4))\n","    plt.style.use('default')\n","    plt.plot(nx1_all[:,i])\n","    plt.plot(nout1_all[:,i],'--',label=\"\")\n","    plt.ylabel(\"Reconstruction\")\n","    plt.xlabel(\"Time Step\")\n","    title = desiredStates[i]\n","    plt.title(title)\n","    plt.ylim((0,1))\n","    plt.savefig(saveTestOutputPath+'test_recon_'+title+'.png', dpi=300)\n","    plt.close()"]},{"cell_type":"code","execution_count":288,"metadata":{},"outputs":[],"source":["for i in range(len(desiredStates)):\n","    plt.figure(figsize=(8,4))\n","    plt.style.use('default')\n","    plt.plot(nx2_all[:,i])\n","    plt.plot(nout2_all[:,i],'--',label=\"\")\n","    plt.ylabel(\"Forward Time Shift Prediction\")\n","    plt.xlabel(\"Time Step\")\n","    title = desiredStates[i]\n","    plt.title(title)\n","    plt.ylim((0,1))\n","    plt.savefig(saveTestOutputPath+'test_fTimeShift_'+title+'.png', dpi=300)\n","    plt.close()"]},{"cell_type":"code","execution_count":289,"metadata":{},"outputs":[],"source":["for i in range(len(desiredStates)):\n","    plt.figure(figsize=(8,4))\n","    plt.style.use('default')\n","    plt.plot(nx3_all[:,i])\n","    plt.plot(nout3_all[:,i],'--',label=\"\")\n","    plt.ylabel(\"Linear Prediction\")\n","    plt.xlabel(\"Time Step\")\n","    title = desiredStates[i]\n","    plt.title(title)\n","    plt.ylim((0,1))\n","    plt.savefig(saveTestOutputPath+'test_linPred_'+title+'.png', dpi=300)\n","    plt.close()"]},{"cell_type":"markdown","metadata":{},"source":["# Animation on Test"]},{"cell_type":"code","execution_count":277,"metadata":{},"outputs":[],"source":["avgTrajErrorList, errorList = avgTrajError(nx1_all, nout1_all, trajLength, numTraj_val)\n","avgTrajErrorArray = np.array(avgTrajErrorList)\n","errorArray = np.array(errorList)\n","errorStdDevArray = np.std(errorArray,axis=0)\n","\n","animateStatesError(avgTrajErrorArray, errorStdDevArray, desiredStates, 'test_recon', mp4FilePath, ifBoundLine=False)\n","\n","avgTrajErrorList, errorList = avgTrajError(nx2_all, nout2_all, trajLength-1, numTraj_val)\n","avgTrajErrorArray = np.array(avgTrajErrorList)\n","errorArray = np.array(errorList)\n","errorStdDevArray = np.std(errorArray,axis=0)\n","\n","animateStatesError(avgTrajErrorArray, errorStdDevArray, desiredStates, 'test_fTimeShiftPred', mp4FilePath, ifBoundLine=False)\n","\n","avgTrajErrorList, errorList = avgTrajError(nx3_all, nout3_all, trajLength-1, numTraj_val)\n","avgTrajErrorArray = np.array(avgTrajErrorList)\n","errorArray = np.array(errorList)\n","errorStdDevArray = np.std(errorArray,axis=0)\n","\n","animateStatesError(avgTrajErrorArray, errorStdDevArray, desiredStates, 'test_linPred', mp4FilePath, ifBoundLine=False)"]},{"cell_type":"markdown","metadata":{},"source":["Trajectory"]},{"cell_type":"code","execution_count":278,"metadata":{},"outputs":[],"source":["animateStates(nout1_all,nx1_all,'Reconstruction','Truth',  desiredStates, 'test_traj_recon')\n","animateStates(nout2_all,nx2_all,'Forward Time Shift','Truth', desiredStates, 'test_traj_FTimeShiftPred')\n","animateStates(nout3_all,nx3_all,'Lin Pred','Truth', desiredStates, 'test_traj_linPred')"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"saveExample.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}
