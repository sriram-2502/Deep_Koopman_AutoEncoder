{"cells":[{"cell_type":"markdown","metadata":{"id":"hrXv0rU9sIma"},"source":["# Implement a custom Autoencoder with Koopman layer"]},{"cell_type":"markdown","metadata":{},"source":["This code is to load a model (only)"]},{"cell_type":"markdown","metadata":{},"source":["## Version Control"]},{"cell_type":"markdown","metadata":{},"source":["To Do:\n","1) Account for trailing batch - Make robust (fixed issue by reshaping input data)\n","4) Validation data has different batch size. Address when HP training"]},{"cell_type":"markdown","metadata":{"id":"3LXMVuV0VhDr"},"source":["## Setup"]},{"cell_type":"code","execution_count":69,"metadata":{"execution":{"iopub.execute_input":"2022-02-26T02:24:32.808146Z","iopub.status.busy":"2022-02-26T02:24:32.807594Z","iopub.status.idle":"2022-02-26T02:24:35.841571Z","shell.execute_reply":"2022-02-26T02:24:35.840833Z"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1649697591026,"user":{"displayName":"Sri Ram","userId":"08645352860667302995"},"user_tz":240},"id":"NiolgWMPgpwI"},"outputs":[],"source":["import tensorflow as tf\n","import matplotlib as mpl\n","from matplotlib import pyplot as plt\n","from tensorflow import keras\n","\n","import  numpy as np\n","import pandas as pd\n","\n","\n","import matplotlib.colors as mcol\n","import matplotlib as mpl\n","from matplotlib import pyplot as plt\n","import matplotlib.animation as animation\n","\n","\n","import time \n","import os\n","\n","import glob"]},{"cell_type":"code","execution_count":70,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1649697591026,"user":{"displayName":"Sri Ram","userId":"08645352860667302995"},"user_tz":240},"id":"Iqo002C_dKA-"},"outputs":[],"source":["plt.rcParams['figure.figsize'] = [9, 6]\n","colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"]},{"cell_type":"code","execution_count":71,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":779,"status":"ok","timestamp":1649697592846,"user":{"displayName":"Sri Ram","userId":"08645352860667302995"},"user_tz":240},"id":"gjzUWH8FdO-d","outputId":"29a19841-26b1-4ec4-96ee-1a44e74e40c7"},"outputs":[],"source":["#from google.colab import drive\n","#drive.mount('/gdrive')"]},{"cell_type":"markdown","metadata":{},"source":["Comment out if don't need"]},{"cell_type":"code","execution_count":72,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1 Physical GPUs, 1 Logical GPUs\n"]}],"source":["gpus = tf.config.experimental.list_physical_devices('GPU')\n","if gpus:\n","    try:\n","        # Currently, memory growth needs to be the same across GPUs\n","        for gpu in gpus:\n","            tf.config.experimental.set_memory_growth(gpu, True)\n","        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n","        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n","    except RuntimeError as e:\n","        # Memory growth must be set before GPUs have been initialized\n","        print(e)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Load the Model from Solid Ground 3 and test on Solid ground 1 and 2 datasets"]},{"cell_type":"code","execution_count":73,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"Koopman_AE_Model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","encoder_model (EncoderModel) multiple                  8480      \n","_________________________________________________________________\n","koopman__model (Koopman_Mode multiple                  256       \n","_________________________________________________________________\n","decoder_model (DecoderModel) multiple                  9700      \n","=================================================================\n","Total params: 18,436\n","Trainable params: 18,436\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["new_model = tf.keras.models.load_model('checkpoints/doggo_Trained_Model', compile=False)\n","new_model.summary()"]},{"cell_type":"markdown","metadata":{},"source":["## Load data"]},{"cell_type":"code","execution_count":74,"metadata":{},"outputs":[],"source":["doggo_train = pd.read_csv('Rigid Ground Data/train_data.csv', sep=',').values\n","doggo_test =pd.read_csv('Rigid Ground Data/test_data_overall.csv', sep=',').values"]},{"cell_type":"code","execution_count":75,"metadata":{},"outputs":[],"source":["desiredStates = ['theta', 'theta_dot',  'gamma', 'gamma_dot']\n","input_dim = len(desiredStates)\n","output_dim = input_dim\n","\n","doggo_train = doggo_train[:,0:input_dim]\n","doggo_test = doggo_test[:,0:input_dim]\n","\n","\n","filePath = \"Graphs and Animations\"\n","fileNames = [filePath + '/Rigid_Ground_1*']\n","\n","\n","trajLength = 64 #length of each trajectory in the dataset\n","numTraj_train = 16 #total number of trajectories in the dataset\n","numTraj_test = 76\n","\n","batch_size = int(256) # Number of snapshots in each batch\n","numTraj_batch = int(batch_size/trajLength)\n","input_dim = 4\n","\n","num_batches_train =  int(trajLength*numTraj_train/batch_size)\n","num_batches_test = int(trajLength*numTraj_test/batch_size)\n"]},{"cell_type":"code","execution_count":76,"metadata":{},"outputs":[{"data":{"text/plain":["256"]},"execution_count":76,"metadata":{},"output_type":"execute_result"}],"source":["numTraj_batch*trajLength"]},{"cell_type":"code","execution_count":77,"metadata":{"executionInfo":{"elapsed":395,"status":"ok","timestamp":1649697594571,"user":{"displayName":"Sri Ram","userId":"08645352860667302995"},"user_tz":240},"id":"mbf4rGRodKBA"},"outputs":[],"source":["doggo_train = np.asarray(doggo_train).astype('float32')\n","doggo_test = np.asarray(doggo_test).astype('float32')"]},{"cell_type":"code","execution_count":78,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Size of doggo_train: 1024\n","Size of doggo_test: 4864\n"]}],"source":["print(\"Size of doggo_train:\", len(doggo_train))\n","print(\"Size of doggo_test:\", len(doggo_test))"]},{"cell_type":"markdown","metadata":{},"source":["### Make into dataset"]},{"cell_type":"code","execution_count":79,"metadata":{"executionInfo":{"elapsed":227,"status":"ok","timestamp":1649697595911,"user":{"displayName":"Sri Ram","userId":"08645352860667302995"},"user_tz":240},"id":"oC-2Gx9KdKBB"},"outputs":[],"source":["# Normalize the data\n","min_val = tf.reduce_min(doggo_train)\n","max_val = tf.reduce_max(doggo_train)\n","\n","doggo_train = (doggo_train - min_val) / (max_val - min_val)\n","doggo_test = (doggo_test - min_val) / (max_val - min_val)\n","\n","train_data = tf.cast(doggo_train[0:batch_size*num_batches_train], tf.float32)\n","test_data = tf.cast(doggo_test, tf.float32)"]},{"cell_type":"code","execution_count":80,"metadata":{},"outputs":[],"source":["x_train = train_data\n","y_train = train_data"]},{"cell_type":"markdown","metadata":{},"source":["# Animate Setup"]},{"cell_type":"code","execution_count":81,"metadata":{},"outputs":[],"source":["Writer = animation.writers['ffmpeg']\n","writer = Writer(fps=20, metadata=dict(artist='Me'), bitrate=1800)"]},{"cell_type":"code","execution_count":82,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["17\n"]}],"source":["mp4FilePath = 'mp4/'\n","try:\n","    os.mkdir(mp4FilePath)\n","except OSError as exc:\n","    print(exc.errno)"]},{"cell_type":"code","execution_count":83,"metadata":{},"outputs":[],"source":["def animateStatesError(middleLine, boundLine, desiredStates:list, titlePrefix, mp4FilePath = 'mp4/', ifBoundLine=True, xlim=[0,64], ylim=[0,1]):\n","    '''\n","    Given the average trajectory error, standard deviation error, and desired states,\n","    animate the trajectory with given legend into a mp4 under the mp4 folder\n","\n","    Parameters:\n","    -----------\n","    middleLine: ndarray\n","        Trajectory of the middle line (nxlen(desiredStates))\n","    boundLine: ndarray\n","        Trajectory of the bound for upper and lower bound (+/- stdDev)\n","    desiredStates: list\n","        List of the desired states\n","    titlePrefix: str\n","        Prefix title to save into mp4FilePath\n","    mp4FilePath: str\n","        Directory path to save mp4\n","    ifBoundLine: Boolean\n","        ifBoundLine is true, graphs with bounded fill between lines, else just graphs middle line\n","    xlim: list\n","        Limit of plot axis in x direction\n","    ylim: list\n","        Limit of axis in y direction\n","\n","\n","    Return:\n","    ---------\n","    None\n","    '''\n","    for j in range(np.shape(middleLine)[1]):\n","        # Set up figure, axis, and plot element want to animate\n","        fig, ax = plt.subplots(figsize=(10,6))\n","        ax.set_xlim(xlim)\n","        ax.set_ylim(ylim)\n","        line, = ax.plot([],[], lw=1, label=desiredStates[j].replace(\"_\", \" \"))\n","        plt.style.use('default')\n","        plt.legend()\n","        plt.tight_layout()\n","\n","        # Initialize function: plot the background of each frame\n","        def init():\n","            line.set_data([], [])\n","\n","            return line,\n","\n","\n","        # animation function called sequentially\n","        def animate(i, j):\n","            x = range(len(middleLine[0:i,j]))\n","            data = middleLine[0:i,j] #select data range\n","            line.set_data(x,data)\n","            line.set_color('#1f77b4')\n","        \n","            if ifBoundLine:\n","                p = plt.fill_between(range(len(boundLine[0:i,j])), middleLine[0:i,j]-boundLine[0:i,j], \n","                                middleLine[0:i,j]+boundLine[0:i,j], facecolor='lightsteelblue')\n","                return line, p,\n","            else:\n","                return line,\n","\n","        anim = animation.FuncAnimation(fig, animate, init_func=init, frames=128,\n","                                    interval=10, repeat=True, blit=True, fargs=(j,))\n","\n","        anim.save(mp4FilePath+titlePrefix+'_'+ desiredStates[j]+'.mp4', writer=writer, dpi=300)\n","        plt.close()"]},{"cell_type":"code","execution_count":84,"metadata":{},"outputs":[],"source":["def animateStates(predictedLine, gTruthLine, label1, label2, desiredStates:list, titlePrefix, mp4FilePath = 'mp4/', ifGTruthLine=True, xlim=[0,64], ylim=[0,1]):\n","    '''\n","    Given the predicted and ground truth trajectory, as well as desired states,\n","    animate the trajectory with given legend into a mp4 under the mp4FilePath folder\n","\n","    Parameters:\n","    -----------\n","    predictedLine: ndarray\n","        Trajectory of the predicted line (nxlen(desiredStates))\n","    gTruthLine: ndarray\n","        Trajectory of the ground truth line (+/- stdDev)\n","    label1: str\n","        Label for predicted line (suffix)\n","    label2: str\n","        Label for ground truth line (suffix)\n","    desiredStates: list\n","        List of the desired states\n","    titlePrefix: str\n","        Prefix title to save into mp4FilePath\n","    mp4FilePath: str\n","        Directory path to save mp4\n","    ifBoundLine: Boolean\n","        ifBoundLine is true, graphs with bounded fill between lines, else just graphs middle line\n","\n","    Return:\n","    ---------\n","    None\n","    '''\n","    for j in range(np.shape(predictedLine)[1]):\n","        # Set up figure, axis, and plot element want to animate\n","        fig, ax = plt.subplots(figsize=(10,6))\n","        ax.set_xlim(xlim)\n","        ax.set_ylim(ylim)\n","        line, = ax.plot([],[], lw=2, linestyle='--', label=desiredStates[j].replace(\"_\", \" \") + \" \" + label1)\n","        line.set_color('C0')\n","        if ifGTruthLine:\n","            line2, = ax.plot([],[], lw=2, linestyle='--', label=desiredStates[j].replace(\"_\", \" \") + \" \" + label2)\n","            line2.set_color('C1')\n","            plt.setp(line2, linestyle='-')\n","        \n","        plt.style.use('default')\n","        plt.legend()\n","        plt.tight_layout()\n","\n","        # Initialize function: plot the background of each frame\n","        def init():\n","            line.set_data([], [])\n","            if ifGTruthLine:\n","                line2.set_data([],[])\n","            return line,\n","\n","\n","        # animation function called sequentially\n","        def animate(i, j):\n","            x = range(len(predictedLine[0:i,j]))\n","            data = predictedLine[0:i,j] #select data range\n","            line.set_data(x,data)\n","            if ifGTruthLine:\n","                line2.set_data(x, gTruthLine[0:i,j])\n","          \n","            return line,\n","\n","        anim = animation.FuncAnimation(fig, animate, init_func=init, frames=128,\n","                                    interval=10, repeat=True, blit=True, fargs=(j,))\n","\n","        anim.save(mp4FilePath+titlePrefix+'_'+ desiredStates[j]+'.mp4', writer=writer, dpi=300)\n","        plt.close()"]},{"cell_type":"markdown","metadata":{},"source":["# Graphing Error Section"]},{"cell_type":"markdown","metadata":{},"source":["#### Average Error Function"]},{"cell_type":"code","execution_count":85,"metadata":{},"outputs":[],"source":["def preProcessForAvg(input, numTraj_batch, trajLength, num_batches, desiredStates, model):\n","    '''\n","    Given input, the number of trajectory in each batch, and the trajector length, outputs\n","    batch data concatenated vertically on top of one another by calling the Koopman AE class\n","\n","    Parameters:\n","    -----------\n","    input: Tensor\n","        Input data to reshape into outputs\n","    numTraj_batch: int\n","        Number of trajectory per batch\n","    trajLength: int\n","        Number of snapshots in a trajectory\n","    desiredStates: list\n","        List of states\n","    model: Koopman AE keras model\n","        Koopman AE model to propagate data\n","\n","    Return:\n","    ----------\n","    x1_all: tensor\n","        Copy of input (No need for change) (Ground Truth)\n","    x2_all: tensor\n","        Concatenated tensor of 1 time shifted data for all batches (Ground Truth)\n","    x3_all: tensor\n","        Concatenated tensor of 1 time step shifted data for all batches (x2_all=x3_all) (Ground Truth)\n","    out1_all: tensor\n","        Reconstruction of input (parameter) using the Koopman AE class\n","    out2_all: tensor\n","        Predicted output from Koopman model of concatenated tensors of 1 time shifted data for all batches\n","    out3_all: tensor\n","        Predicted n time step output from Koopman model of concatenated tensors data for all batches\n","    '''\n","    \n","    x2_all = []\n","    out1_all = []\n","    out2_all = []\n","    out3_all = []\n","    x = input\n","\n","    for i in range(num_batches):\n","        x2 = []\n","        \n","        for j in range(numTraj_batch):\n","            x2.append(x[(i*numTraj_batch+j)*trajLength+1:(i*numTraj_batch+j+1)*trajLength])\n","        \n","        x2 = tf.reshape(x2, [-1, x.shape[-1]]) # Shifted input for a batch\n","        x2_all.append(x2)\n","        \n","        x_input = x[i*numTraj_batch*trajLength:(i+1)*numTraj_batch*trajLength]\n","        \n","        out1, out2, out3 = model(x_input)\n","        out1_all.append(out1)\n","        out2_all.append(out2)\n","        out3_all.append(out3)\n","        \n","    x1_all = x\n","    x2_all = tf.reshape(x2_all,(-1,len(desiredStates)))\n","    x3_all = x2_all\n","    out1_all = tf.reshape(out1_all,(-1,len(desiredStates)))\n","    out2_all = tf.reshape(out2_all,(-1,len(desiredStates)))\n","    out3_all = tf.reshape(out3_all,(-1,len(desiredStates)))\n","\n","\n","    '''\n","    print(tf.shape(x2_all))\n","    print(tf.shape(out1_all))\n","    print(tf.shape(out2_all))\n","    print(tf.shape(out3_all))\n","    '''\n","\n","    return x1_all, x2_all, x3_all, out1_all, out2_all, out3_all"]},{"cell_type":"code","execution_count":86,"metadata":{},"outputs":[],"source":["def avgTrajError(gTruth, predicted, trajLength, numTraj):\n","    '''\n","    Get the average trajectory error with min and max values (Maybe std dev better)\n","\n","    Parameters:\n","    -----------\n","    gTruth: tensor or ndarray\n","        Ground Truth matrix\n","    predicted: tensor or ndarray\n","        Predicted matrix\n","    trajLength: int\n","        Length of trajectory\n","    numTraj: int\n","        Number of trajectory (total?)\n","    \n","\n","    Return:\n","    ----------\n","    avgErrorList: list\n","        List of average errors of all trajectories (each index is the avg error of the states at a point of time along the trajectory)\n","    \n","    errorList: list\n","        List of error of all states and trajectory\n","    '''\n","    errorList = []\n","    avgErrorList = []\n","    numStates = len(gTruth[0,:])\n","    for i in range(numTraj):\n","        '''\n","        print(\"Gtruth\")\n","        print(np.array(gTruth)[i*trajLength:(i+1)*trajLength,:])\n","        print(\"Predicted\")\n","        print(np.array(predicted[i*trajLength:(i+1)*trajLength,:]))\n","        print(\"---Loop---\")\n","        '''\n","        errorList.append(np.array(gTruth)[i*trajLength:(i+1)*trajLength,:] - np.array(predicted[i*trajLength:(i+1)*trajLength,:]))\n","    \n","    #print(\"Error List\")\n","    #print(np.shape(errorList[0]))\n","    \n","    for j in range(trajLength):\n","        #print(\"Length of Traj %d\"% j)\n","        for k in range(numTraj):\n","            #print(\"Traj: %d\"% k)\n","            if k == 0:\n","                avgErrorList.append(errorList[k][j,:])\n","            else:\n","                #print(avgErrorList[j])\n","                avgErrorList[j] = (k*avgErrorList[j]+errorList[k][j,:])/(k+1) # Recursive average formula\n","    return avgErrorList, errorList"]},{"cell_type":"markdown","metadata":{},"source":["# Test Graphs"]},{"cell_type":"code","execution_count":87,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["17\n"]}],"source":["saveTestOutputPath = 'testOutputGraph/'\n","try:\n","    os.mkdir(saveTestOutputPath)\n","except OSError as exc:\n","    print(exc.errno)"]},{"cell_type":"code","execution_count":88,"metadata":{},"outputs":[],"source":["nx1_all,nx2_all,nx3_all,nout1_all,nout2_all,nout3_all = preProcessForAvg(doggo_test, numTraj_batch, trajLength, num_batches_test, desiredStates, new_model)"]},{"cell_type":"markdown","metadata":{},"source":["### batch traj plots"]},{"cell_type":"code","execution_count":108,"metadata":{},"outputs":[],"source":["for i in range(len(desiredStates)):\n","    #plt.figure(figsize=(8,4))\n","    plt.style.use('default')\n","    plt.plot(nx1_all[0:batch_size,i], label=\"Ground Truth\")\n","    plt.plot(nout1_all[0:256,i],'--',label=\"Reconstruction\")\n","    plt.ylabel(\"Reconstruction\")\n","    plt.xlabel(\"Time Step\")\n","    title = desiredStates[i]\n","    plt.title(title)\n","    plt.legend()\n","    #plt.ylim((min1,max1))\n","    plt.savefig(saveTestOutputPath+'test_recon_'+title+'.png', dpi=300)\n","    plt.close()"]},{"cell_type":"code","execution_count":109,"metadata":{},"outputs":[],"source":["for i in range(len(desiredStates)):\n","    #plt.figure(figsize=(8,4))\n","    plt.style.use('default')\n","    plt.plot(nx2_all[0:batch_size,i], label=\"Ground Truth\")\n","    plt.plot(nout2_all[0:batch_size,i],'--',label=\" One time step prediction\")\n","    plt.ylabel(\"Forward Time Shift Prediction\")\n","    plt.xlabel(\"Time Step\")\n","    title = desiredStates[i]\n","    plt.title(title)\n","    plt.legend()\n","    #plt.ylim((min2,max2))\n","    plt.savefig(saveTestOutputPath+'test_fTimeShift_'+title+'.png', dpi=300)\n","    plt.close()"]},{"cell_type":"code","execution_count":110,"metadata":{},"outputs":[],"source":["for i in range(len(desiredStates)):\n","    #plt.figure(figsize=(8,4))\n","    plt.style.use('default')\n","    plt.plot(nx3_all[0:batch_size,i], label=\"Ground Truth\")\n","    plt.plot(nout3_all[0:batch_size,i],'--',label=\"Full trajectory prediction\")\n","    plt.ylabel(\"Linear Prediction\")\n","    plt.xlabel(\"Time Step\")\n","    title = desiredStates[i]\n","    plt.title(title)\n","    plt.legend()\n","    #plt.ylim((min3,max3))\n","    plt.savefig(saveTestOutputPath+'test_linPred_'+title+'.png', dpi=300)\n","    plt.close()"]},{"cell_type":"markdown","metadata":{},"source":["# Animation on Test"]},{"cell_type":"code","execution_count":92,"metadata":{},"outputs":[],"source":["avgTrajErrorList, errorList = avgTrajError(nx1_all, nout1_all, trajLength, numTraj_test)\n","avgTrajErrorArray = np.array(avgTrajErrorList)\n","errorArray = np.array(errorList)\n","errorStdDevArray = np.std(errorArray,axis=0)\n","\n","animateStatesError(avgTrajErrorArray, errorStdDevArray, desiredStates, 'test_recon_error', mp4FilePath, ifBoundLine=False)\n","\n","avgTrajErrorList, errorList = avgTrajError(nx2_all, nout2_all, trajLength-1, numTraj_test)\n","avgTrajErrorArray = np.array(avgTrajErrorList)\n","errorArray = np.array(errorList)\n","errorStdDevArray = np.std(errorArray,axis=0)\n","\n","animateStatesError(avgTrajErrorArray, errorStdDevArray, desiredStates, 'test_fTimeShiftPred_error', mp4FilePath, ifBoundLine=False)\n","\n","avgTrajErrorList, errorList = avgTrajError(nx3_all, nout3_all, trajLength-1, numTraj_test)\n","avgTrajErrorArray = np.array(avgTrajErrorList)\n","errorArray = np.array(errorList)\n","errorStdDevArray = np.std(errorArray,axis=0)\n","\n","animateStatesError(avgTrajErrorArray, errorStdDevArray, desiredStates, 'test_linPred_error', mp4FilePath, ifBoundLine=False)"]},{"cell_type":"markdown","metadata":{},"source":["Trajectory"]},{"cell_type":"code","execution_count":104,"metadata":{},"outputs":[],"source":["animateStates(nout1_all,nx1_all,'Reconstruction','Truth',  desiredStates, 'test_traj_recon',xlim=[0,64], ylim=[-0.1,0.1])\n","animateStates(nout2_all,nx2_all,'Forward Time Shift','Truth', desiredStates, 'test_traj_FTimeShiftPred', xlim=[0,64], ylim=[-0.1,0.1])\n","animateStates(nout3_all,nx3_all,'Lin Pred','Truth', desiredStates, 'test_traj_linPred', xlim=[0,64], ylim=[-0.1,0.1])"]},{"cell_type":"markdown","metadata":{},"source":["### Error Graphs with std dev"]},{"cell_type":"code","execution_count":94,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["17\n"]}],"source":["saveErrorPath = 'errorGraph/'\n","try:\n","    os.mkdir(saveErrorPath)\n","except OSError as exc:\n","    print(exc.errno)"]},{"cell_type":"markdown","metadata":{},"source":["### Reconstruction error graph with std dev"]},{"cell_type":"code","execution_count":95,"metadata":{},"outputs":[],"source":["avgTrajErrorList, errorList = avgTrajError(nx1_all, nout1_all, trajLength, numTraj_test)\n","avgTrajErrorArray = np.array(avgTrajErrorList)\n","errorArray = np.array(errorList)\n","errorStdDevArray = np.std(errorArray,axis=0)"]},{"cell_type":"code","execution_count":96,"metadata":{},"outputs":[],"source":["for i in range(len(desiredStates)):\n","    plt.figure()\n","    plt.style.use('default')\n","    plt.plot(avgTrajErrorArray[:,i])\n","    plt.fill_between(range(len(errorStdDevArray[:,i])), avgTrajErrorArray[:,i]-errorStdDevArray[:,i], avgTrajErrorArray[:,i]+errorStdDevArray[:,i],alpha = 0.3)\n","    title=desiredStates[i]\n","    plt.title(title)\n","    plt.ylabel(\"Reconstruction Error\")\n","    plt.xlabel(\"Time Step\")\n","    #plt.ylim((0,1))\n","    plt.savefig(saveErrorPath+'recon_error_'+title+'.png', dpi=300)\n","    plt.close()"]},{"cell_type":"markdown","metadata":{},"source":["### Forward time shift prediction graphs with std dev (use traj len - 1)"]},{"cell_type":"code","execution_count":97,"metadata":{},"outputs":[],"source":["avgTrajErrorList, errorList = avgTrajError(nx2_all, nout2_all, trajLength-1, numTraj_test)\n","avgTrajErrorArray = np.array(avgTrajErrorList)\n","errorArray = np.array(errorList)\n","errorStdDevArray = np.std(errorArray,axis=0)"]},{"cell_type":"code","execution_count":98,"metadata":{},"outputs":[{"data":{"text/plain":["(76, 63, 4)"]},"execution_count":98,"metadata":{},"output_type":"execute_result"}],"source":["errorArray.shape"]},{"cell_type":"code","execution_count":99,"metadata":{},"outputs":[],"source":["for i in range(len(desiredStates)):\n","    plt.figure()\n","    plt.style.use('default')\n","    plt.plot(avgTrajErrorArray[:,i])\n","    plt.fill_between(range(len(errorStdDevArray[:,i])), avgTrajErrorArray[:,i]-errorStdDevArray[:,i], avgTrajErrorArray[:,i]+errorStdDevArray[:,i],alpha = 0.3)\n","    title=desiredStates[i]\n","    plt.title(title)\n","    plt.ylabel(\"Forword time shift error\")\n","    plt.xlabel(\"Time Step\")\n","    #plt.ylim((0,1))\n","    plt.savefig(saveErrorPath+'fTimeshift_error_'+title+'.png', dpi=300)\n","    plt.close()"]},{"cell_type":"markdown","metadata":{},"source":["#### Linear prediction graphs with std dev (use traj len -1)"]},{"cell_type":"code","execution_count":100,"metadata":{},"outputs":[],"source":["avgTrajErrorList, errorList = avgTrajError(nx3_all, nout3_all, trajLength-1, numTraj_test)\n","avgTrajErrorArray = np.array(avgTrajErrorList)\n","errorArray = np.array(errorList)\n","errorStdDevArray = np.std(errorArray,axis=0)"]},{"cell_type":"code","execution_count":101,"metadata":{},"outputs":[],"source":["for i in range(len(desiredStates)):\n","    plt.figure()\n","    plt.style.use('default')\n","    plt.plot(avgTrajErrorArray[:,i])\n","    plt.fill_between(range(len(errorStdDevArray[:,i])), avgTrajErrorArray[:,i]-errorStdDevArray[:,i], avgTrajErrorArray[:,i]+errorStdDevArray[:,i],alpha = 0.3)\n","    title=desiredStates[i]\n","    plt.title(title)\n","    plt.ylabel(\"Linear prediction error\")\n","    plt.xlabel(\"Time Step\")\n","    #plt.ylim((0,1))\n","    plt.savefig(saveErrorPath+'lin_pred_error_'+title+'.png', dpi=300)\n","    plt.close()"]},{"cell_type":"code","execution_count":102,"metadata":{},"outputs":[],"source":["animateStatesError(avgTrajErrorArray, errorStdDevArray, desiredStates, 'test_recon_error', mp4FilePath, ifBoundLine=False)\n","animateStatesError(avgTrajErrorArray, errorStdDevArray, desiredStates, 'test_fTimeShiftPred_error', mp4FilePath, ifBoundLine=False)\n","animateStatesError(avgTrajErrorArray, errorStdDevArray, desiredStates, 'test_linPred_error', mp4FilePath, ifBoundLine=False)"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"saveExample.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}
