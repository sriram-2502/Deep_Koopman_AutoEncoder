enc layers: 3
enc units [16,32,64], act:[elu,elu,elu]
Koopman Layer: 1 
Koopman units: 64, act: None
dec layers: 3
dec units [32,16,2], act: [elu,elu,elu]

training paramters
epochs: 250
learning_rate: 1e-4

Loss: alpha1 = 1, alpha2 = 1e-5, alpha3 = 1e-10

batch_size = 256
trajectory_Length = 64
NumTraj = 1024
Num_batches = 128
Num_batches_val = 128


